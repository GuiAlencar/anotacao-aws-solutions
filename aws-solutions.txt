AWS solutions Architect Associate

IaaS -> Infra como serviço, paga para utilizar a infra da aws, usado como serviço
	você gerencia -> Applications, data, runtime, middleware, S.O
	AWS gerencia  -> Virtualização, serves, storage, networking
	
	ex.: instâncias EC2

Paas -> Plataforma como serviço
	você gerencia -> Applications, data
	AWS gerencia  -> runtime, middleware, S.O, Virtualização, serves, storage, networking

	ex.: elastic beanstalk

SaaS -> software como serviço 
	você gerencia -> nada
	AWS gerencia  -> Applications, data, runtime, middleware, S.O, Virtualização, serves, storage, networking

	ex.: CRM, OFFICE 365, GMAIL

---------------------------

Public cloud -> Aws, neste caso, qualquer um com interesse em usar os serviços da aws

Hybrid cloud -> publico + privado, serviços no público, mas assuntos mais sigilosos estão no privado

Private cloud -> servidor privado com um custo mais elevado

---------------------------

AWS Wavelength
* Permite aos desenvolvedores criar aplicativos com latências inferiores a 10 milissegundos para dispositivos móveis e usuários finais.
* incorpora serviços de computação e armazenamento da aws em redes 5G, fornecendo infraestrutura de computação móvel de ponta para desenvolver, implantar e dimensionar aplicativos de latência ultrabaixa
---------------------------

AWS outposts
* Com o AWS Outposts, você pode executar alguns produtos da AWS localmente e se conectar a uma ampla gama de serviços disponíveis na região local da AWS
* O outposts traz  data center da AWS diretamente para você, no local. O outposts permite que você tenha uma grande variedade de serviços aws em seu data center. Você pode ter outposts em tamanhos como 
  servidores de 1U e 2U até racks de 42U e implantações de vários racks.

Benefícios:
* nuvem híbrida: crie uma nuvem híbrida onde você possa aproveitar os serviços da aws dentro do seu próprio data center.
* infraestrutura totalmente gerenciada: a aws pode gerenciar a infraestrutura para você. Você não precisa de uma equipe dedicada para cuidar da infraestrutura de outposts.
* consistência: leve o aws management console, as APIs e os SDKs para o seu data center, permitindo consistência uniforme no seu ambiente híbrido.

Membro da família outposts
* Outposts rack
  * hardware: disponível começando com um único rack de 42U e ampliando até 96 racks
  * serviços: fornece computação, armazenamento, banco de dados e outros serviços da aws localmente
  * resultados: oferece a mesma infraestrutura, serviços e APIs da aws em seu próprio data center

* Outposts Serves
  * hardware: servidores individuais em formato 1U ou 2U
  * casos de uso: útil para requisitos de espaço pequeno, como lojas de varejo, filiais, locais de prestação de serviços de saúde ou chão de fábrica
  * resultado: fornece serviços locais de computação e rede

Processo
* pedido: faça login no aws management console e solicite a configuração do outposts.
* instalar: a equipe da aws estará no local para instalar e implantar o hardware, incluindo energia, rede e conectividade
* lançamento: usando o aws management console, você pode executar instâncias no outposts no local.
* build: comece a construir seu ambiente aws local
---------------------------

IAM: identity and Access Management - global service
é possível chegar no iam das seguintes formas: console, cli, api
O iam permite gerenciar usuários e seu nível de acesso ao console AWS.
Podemos gerenciar as políticas como:  IBP e RBP e depois poder criar os serviços, exemplo : ec2, s3 
 * crie usuários e conceda permissões a eles.
 * crie grupos e funções
 * controle o acesso aos recursos da AWS

IAM: Usuários e Grupos
• IAM = Gerenciamento de Identidade e Acessos, serviço global
• A conta raiz é criada por padrão, mas não deve ser usada ou compartilhada
• Usuários são pessoas dentro da sua organização e podem ser agrupados
• Grupos contêm apenas usuários, não outros grupos
• Usuários não precisam pertencer a um grupo, e um usuário pode pertencer a vários grupos

IAM: Permissões
• Usuários ou Grupos podem ser atribuídos a documentos JSON chamados políticas
• Essas políticas definem as permissões dos usuários
• Na AWS, aplica-se o princípio do menor privilégio: não conceda mais permissões do que um usuário precisa

-------------------------
Estrutura de Políticas IAM
• Consiste em:
• Version: versão da linguagem de política, sempre incluir "2012-10-17"
• Id: um identificador para a política (opcional)
• Statement: uma ou mais declarações individuais (obrigatório)

• Declarações consistem em:
• Sid: um identificador para a declaração (opcional)
• Effect: se a declaração permite ou nega acesso (Allow, Deny)
• Principal: conta/usuário/função à qual essa política se aplica
• Action: lista de ações que essa política permite ou nega
• Resource: lista de recursos aos quais as ações se aplicam
• Condition: condições para quando essa política está em vigor (opcional)
-------------------------
Protegendo a conta root
  * habilite a autenticação de dois fatores
  * crie um grupo de administradores para seus administradores e atribua as permissões apropriadas a esse grupo.
  * crie contas de usuário para seus administradores
  * adicione seus usuários ao grupo de administradores

Como controlamos as permissões usando o IAM ?
* atribuímos permissões usando documentos de política, que são compostos de JSON

documento de política do IAM
* grupos, funções
  |----> usuários (alerta: é uma boa prática o usuário herdar a política do grupo para ficar fácil de gerenciar)

identity policy vs resource policy

identity policy: user -> política de inline 1 para 1 -> role, não conseguimos aplicar a inline para um grupo por que afeta mais de um.
		 aws manged ou customer manage por ser aplicada para um user para um grupo e para role

resource policy: aplica para um recurso, exemplo: s3, ec2, o guilherme pode fazer upload no s3 ou um shutdown no ec2

==================================================================================

S3 -> simple storage servisse

exemplos de URLs S3:
 https://bucket-name.s3.Region.amazonaws.com/key-name
 https://acloudguru.s3.us-east-1.amazonaws.com/Ralphie.jpg

Fazendo upload de arquivos
* Ao fazer upload de um arquivo para um bucket, você receberá um código HTTP 200 se o upload for bem sucedido.

S3 Standard : oferece um armazenamento de objetos com altos níveis de resiliência, disponibilidade e performance para dados acessados com frequência.
	      * Armazenamento de uso geral para dados acessados com frequência	
              *	Performance com baixa latência e alto throughput
              * Projetado para oferecer disponibilidade de 99,99% com um SLA de disponibilidade de 99,9%
	      * Durabilidade 99.999999999%
              * casos de uso -> como aplicações na nuvem, sites dinâmicos, distribuição de conteúdo, aplicações móveis e de jogos e análise de big data. 
	      * tamanho mínimo 1 byte e tamanho máximo 5TB
	      * dados são armazenados de forma redundante em vários dispositivos em diversas instalações (>=3 AZs)

S3 Intelligent-Tiering: Move automaticamente seus dados para o nível mais econômico com base na frequência com que você acessa cada objeto
		* disponibilidade de 99,9% 
		* durabilidade de 99.99999999999%


S3 Express One Zone: é uma classe de armazenamento de alta performance com zona de disponibilidade única criada especificamente para oferecer acesso 		       consistente a dados na velocidade de um dígito em milissegundos para seus dados acessados com mais frequência e aplicações sensíveis à 		       latência.

S3 Standard-Infrequent Access (S3 Standard-IA): O S3 Standard-IA é indicado para dados acessados com menos frequência, mas que exigem acesso rápido quando 		necessários. 

		exemplo:
		* acesso rápido: usado para dados acessados com menos frequência, mas que exigem acesso rápido quando necessário
		* você paga para acessar os dados: há um preço baixo de armazenamento por GB e uma taxa de recuperação por GB
		* casos de uso: ótimo para armazenamento de longo prazo, backups e como armazenamento de dados para arquivos de recuperação de desastres

S3 One Zone-Infrequent Access (S3 One Zone-IA): O S3 One Zone-IA é indicado para dados acessados com menos frequência, mas que exigem acesso rápido quando 		necessários. Ao contrário de outras classes de armazenamento do S3, que armazenam dados em no mínimo três Zonas de disponibilidade (AZs), a 		S3 One Zone-IA armazena dados em uma única AZ, com um custo 20% inferior ao S3 Standard-IA.

		exemplo:
		Dados recriáveis acessados com pouca frequência
		A mesma performance de baixa latência e alto throughput da categoria S3 Standard
		Projetado para oferecer disponibilidade de 99,5% com um SLA de disponibilidade de 99%

S3 Glacier Instant Retrieval: A Amazon S3 Glacier Instant Retrieval é uma classe de armazenamento de arquivos que oferece o armazenamento de custo mais 		baixo para dados de longa duração, que raramente são acessados e exigem recuperação em milissegundos.
		
		exemplo:
		Dados de longa duração que são acessados algumas vezes por ano com recuperações instantâneas
		Recuperação de dados em milissegundos com a mesma performance do S3 Standard
		Projetado para oferecer disponibilidade de 99,9% com um SLA de disponibilidade de 99%
		128 KB de tamanho mínimo do objeto
		API PUT do S3 para uploads diretos ao S3 Glacier Instant Retrieval e gerenciamento do S3 Lifecycle para migração automática de objetos

Glacier Flexible Retrieval (anteriormente S3 Glacier): classe de armazenamento ideal para dados arquivados que não exigem acesso imediato, mas precisam de 
		flexibilidade para recuperar grandes conjuntos de dados sem nenhum custo, como casos de uso de backup ou recuperação de desastres. Pode 
		durar minutos ou até 12 horas.
	

S3 Glacier Deep Archive: classe de armazenamento mais barata e projetada para clientes que retêm conjuntos de dados por 7 a 10 anos ou mais para atender
		as necessidades do cliente e aos requisitos de conformidade regulatória. O tempo de recuperação padrão é de 12 horas e o tempo de 
		recuperação em massa é de 48 horas



S3 no Outposts: O Amazon S3 on Outposts oferece armazenamento de objetos para seu ambiente de AWS Outposts on-premises. Usando as APIs S3 e os recursos 		disponíveis nas regiões da AWS hoje, o S3 on Outposts torna mais fácil armazenar e recuperar dados em seu Outpost, bem como proteger os 		dados, controlar o acesso, marcar e gerar relatórios sobre eles.

		exemplo:
		Compatibilidade de objetos do S3 e gerenciamento de bucket via SDK do S3
		Projetado para armazenar dados de maneira duradoura e redundante em seus Outposts
		Criptografia usando SSE-S3 e SSE-C
		Autenticação e autorização usando IAM e pontos de acesso S3
		Transferir dados para regiões AWS usando AWS DataSync
		Ações de expiração de ciclo de vida do S3

DICA PARA A PROVA
* Os buckets são privados por padrão: quando você cria um bucket do S3, ele é privado por padrão (incluindo todos os objetos dentro dele). Você deve permitir o acesso ao bucket e a seus objetos para tornar o bucket público.

* ACLs de objeto: você pode tornar públicos objetos individuais usando ACLs de objeto.
* Políticas de bucket: você pode tornar públicos todo o bucket usando politicas de bucket
* Código de status HTTP: ao fazer upload de um objeto para o S3 e ele for bem sucedido, você receberá um código HTTP 200

S3 é dimensionado automaticamente para atender a demanda. Muitas empresas colocarão sites estáticos no s3 quando acharem que haverá um grande número de solicitações (por exemplo, para uma prévia de um filme).


--------------------------------------------------
Protegendo seus dados

* criptografia do lado do servidor: você pode definir a criptografia padrão em um bucket para criptografar todos os novos objetos quando eles foram
  armazenados no bucket
* listas de controle de acesso (ACLs): defina quais contas ou grupos da aws terão acesso e o tipo de acesso. Você pode anexar ACLs do S3 a objetos
  individuais em um bucket
* Bucket policies: as políticas de bucket S3 especificam quais ações são permitidas ou negadas (por exemplo, que o user Alice coloque, mas não delete
  objetos no bucket).

--------------------------------------------------
Vantagens do Versionamento do S3
* todas as versões: todas as versões de um objeto são armazenados no s3. isso inclui todas as gravações e até mesmo se você excluir um objeto
* Backup: pode ser ótima ferramenta de backup
* não pode ser desativado: uma vez ativado, o versionamento não pode ser desativado, - apenas suspenso
* regas de clico de vida: pode ser integrado as regras do ciclo de vida
* suporta MFA: pode suportar autenticação de dois fatores
--------------------------------------------------
Gerenciamento de lifecycle
* O gerenciamento do ciclo de vida automatiza a movimentação de seus objetos entre as diferentes camadas de armazenamento, maximizando assim a relação custo benefício

S3 Standard                   S3 IA             Glacier
     |                          |                  |
manter por 30 dias          após 30 dias        após 90 dias

combinando gerenciamento do ciclo de vida com controle de versão
* você pode usar o gerenciamento de ciclo de vida para mover diferentes versões de objetos para diferentes níveis de armazenamento.
* pode ser aplicado para versões atuais e versões anteriores.


--------------------------------------------------
S3 object Lock/bloqueio de objeto do s3

* você pode usar o s3 object lock para armazenar objetos usando um modelo de gravação único e leitura múltipla(WORM). Pode ajudar a evitar que objetos
  sejam excluídos ou modificados por um período fixo ou indefinidamente.
* Você pode usar o S3 object lock para atender aos requisitos regulatórios que exigem armazenamento WORM ou adicionar uma camada extra de proteção contra
  alterações e exclusões de objetos.

Modo Governança
* No modo de governança, os utilizadores não podem substituir ou eliminar uma versão de objeto ou alterar as suas definições de bloqueio, a menos que tenham
  permissões especiais
* Com o modo de governança, você protege os objetos contra exclusão pela maioria dos usuários, mas ainda pode conceder permissão a alguns usuários para
  alterar as configurações de retenção ou excluir o objeto, se necessário.

Modo de conformidade
* No modo de conformidade, uma versão de objeto protegido não pode ser substituída ou excluída por nenhum usuário, incluindo o usuário root na sua conta 
  da AWS. Quando um objeto está bloqueado no modo de conformidade, seu modo de retenção não pode ser alterado e seu período de retenção não pode ser
  reduzido. O modo de conformidade garante que uma versão do objeto não possa ser substituída ou excluída durante o período de retenção

Período de retenção
* um período de retenção protege uma versão do objeto por um período fixo de tempo. Quando você coloca um período de retenção em um versão do objeto, o 
  amazona s3 armazena um carimbo de data/hora nos metadado da versão do objeto para indicar quando o período de retenção expira.
* Depois que o período de retenção expirar, a versão do objeto poderá ser substituída ou excluída, a menos que você também tenha colocado uma retenção legal
  na versão do objeto.

Retenção Legais
* O s3 object lock também permite colocar uma retenção legal em uma versão do objeto. Assim como um período de retenção, uma retenção legal impede que uma
  versão do objeto seja substituída ou excluída. No entanto, uma retenção legal não tem um período de retenção associado e permanece em vigor até ser 
  removida. As retenções legais podem ser colocadas e removidas livremente por qualquer usuário que tenha a permissão s3:PutObjectLegalHold

Glacier Vault Lock
* Adota um modelo WORM (Write Once, Read Many).
* Criação de uma Vault Lock Policy.
* Travar a política para edições futuras (não poderá mais ser alterada ou excluída).
* Útil para conformidade e retenção de dados.
--------------------------------------------------
criptografia do S3
Encryption in transit: SSL/TLS, HTTPS

server-side encryption 
 * Todos os buckets do s3 têm criptografia por padrão. Todos os objetos são criptografados automaticamente usando criptografia server-side encryption com 
   chaves gerenciadas do s3 (SSE-S3)
 * SSE-S3 - acontece do lado da bucket, encriptado no momento que é mandado para bucket, quando feito download é decriptado.
         - s3 gerencia as chaves
	 - usa AES 256-bit encryption

 * SSE-KMS - criptografia gerenciado pelo serviço do KMS 
	   - aqui o serviço KMS gerencia sua chave

 * SSE-C (client) - Aqui o cliente gerencia suas chaves de criptografia
                  - cliente fornece a chave de criptografia

cliente-side encryption
 * CSE - o cliente encripta os arquivos antes de enviar e quando é feito do download o cliente tem que decriptar
       - chaves são armazenadas pelo cliente

 Enforcing Encryption
 * aplicando criptografia com uma politica de bucket
 * uma politica de bucket pode negar todas as solicitações PUT que não incluam o parâmetro x-amz-server-side-encryption no cabeçalho da solicitação.
 
------------------------------------

Amazon S3 – Criptografia de Objetos
Você pode criptografar objetos em buckets do S3 usando um dos 4 métodos:

Criptografia no Lado do Servidor (SSE)
	* Criptografia no Lado do Servidor com Chaves Gerenciadas pelo Amazon S3 (SSE-S3) – Habilitada por padrão
	* Criptografa objetos no S3 usando chaves manipuladas, gerenciadas e de propriedade da AWS.	
	* Criptografia usando chaves manipuladas, gerenciadas e de propriedade da AWS.
	* O objeto é criptografado no lado do servidor.
	* O tipo de criptografia utilizado é AES-256.
	É necessário definir o cabeçalho:
	  "x-amz-server-side-encryption": "AES256"
	* Habilitado por padrão para novos buckets e novos objetos.
	
Criptografia no Lado do Servidor com Chaves KMS armazenadas no AWS KMS (SSE-KMS)
	* Utiliza o AWS Key Management Service (AWS KMS) para gerenciar as chaves de criptografia.
	* Criptografia usando chaves manipuladas e gerenciadas pelo AWS KMS (Key Management Service).
	* Vantagens do KMS:
		Maior controle do usuário sobre as chaves.
		Possibilidade de auditar o uso das chaves usando o AWS CloudTrail.
	* O objeto é criptografado no lado do servidor.
	É necessário definir o cabeçalho:
	  "x-amz-server-side-encryption": "aws:kms"
	
Criptografia no Lado do Servidor com Chaves Fornecidas pelo Cliente (SSE-C)
	* Quando você deseja gerenciar suas próprias chaves de criptografia.
	* Criptografia no lado do servidor usando chaves totalmente gerenciadas pelo cliente fora da AWS.
	* O Amazon S3 NÃO armazena a chave de criptografia fornecida pelo cliente.
	* O uso de HTTPS é obrigatório para proteger a transmissão da chave.
	* A chave de criptografia deve ser fornecida nos cabeçalhos HTTP em todas as requisições HTTP feitas.
	
Criptografia no Lado do Cliente
	* Utiliza bibliotecas de criptografia no lado do cliente, como a Amazon S3 Client-Side Encryption Library.
	* O cliente deve criptografar os dados antes de enviá-los para o Amazon S3.
	* O cliente também deve descriptografar os dados ao recuperá-los do Amazon S3.
	* O cliente gerencia completamente as chaves e o ciclo de criptografia.

Amazon S3 – Criptografia em Trânsito (SSL/TLS)
A criptografia em trânsito também é chamada de SSL/TLS.
O Amazon S3 expõe dois endpoints:
	Endpoint HTTP – não criptografado.
	Endpoint HTTPS – criptografia em trânsito.
Recomenda-se o uso de HTTPS.
HTTPS é obrigatório para SSE-C.
A maioria dos clientes usa o endpoint HTTPS por padrão.

--------------------------------------------------
O que é CORS?
CORS (Cross-Origin Resource Sharing) – Compartilhamento de Recursos entre Origens Diferentes.
Origem (Origin) = esquema (protocolo) + host (domínio) + porta.
	Exemplo: https://www.example.com (a porta implícita é 443 para HTTPS e 80 para HTTP).
Mecanismo baseado em navegador que permite requisições para outras origens enquanto visita a origem principal.
Mesma origem: http://example.com/app1 & http://example.com/app2.
Origens diferentes: http://www.example.com & http://other.example.com.
As requisições não serão atendidas a menos que a outra origem permita usando Cabeçalhos CORS (exemplo: Access-Control-Allow-Origin).

--------------------------------------------------

S3 Reduced Redundancy Storage - O Reduced Redundancy Storage (RRS) é uma opção de armazenamento do Amazon S3 que permite aos clientes armazenar dados reproduzíveis e que não sejam de fundamental importância com níveis de redundância mais baixos do que o armazenamento padrão do Amazon S3.

   - Disponibilidade amparada pelo Acordo de Nível de Serviço do Amazon S3
   - Projetado para fornecer 99,99% de durabilidade e 99,99% de disponibilidade de objetos em um determinado ano. Esse nível de durabilidade corresponde a uma perda anual esperada média de 0,01% de objetos.
   - Projetado para sustentar a perda de dados em uma única instalação.


--------------------------------------------------
Otimizando o desempenho do S3

KMS request rates/taxa de solicitação KMS
  * O upload/download contará para a cota KMS
  * atualmente, não é possível solicitar um aumento de cota para o KMS
  * no entanto, epecifico da região, são 5500, 10000 ou 30000 solicitações por segundo

S3 performance:Uploads

  Multipart Uploads/uploads fracionados
  * recomendado para arquivos com mais de 100 MB
  * obrigatório para arquivos com mais de 5 GB
  * paralelize uploads (aumenta a eficiência)

  Transferir arquivos com falha na rede -> usar o multipart upload para o Amazon S3
  * Você pode usar um multipart upload para fazer upload de arquivos maiores, como os arquivos nesse cenário. Se a transmissão de alguma parte falhar, 
    você poderá retransmitir essa parte sem afetar as outras.

S3 performance:Downloads
 S3 byte-range fetches/buscas de intervalo de bytes S3
  * paralelize downloads especificando intervalos de bytes
  * se houver falha no download, é apenas para um intervalo de bytes especifico
  * exemplo, arquivo de 5 GB pode baixar 1 GB por vez 

--------------------------------------------------
Replicação S3
* você pode replicar objetos de um bucket para outro, o controle de versão deve estar habilitado nos buckets de origem e de destino
* os objetos em um bucket existente não são replicados automaticamente, depois que a replicação for ativada, todos os objetos atualizados subsequentes
  serão replicados automaticamente
* os marcadores de exclusão não são replicados por padrão, a exclusão de versões individuais ou de exclusão de marcadores não será replicada
==================================================================================

>>>EC2<<<
Definição de valores

on-demand -> pague por hora ou segundo, dependendo do tipo de instância que você executa
  * Flexível: baixo custo e flexibilidade do amazona EC2 sem qualquer pagamento antecipado ou compromisso de longo prazo
  * curto prazo: aplicativos com cargas de trabalho de curto prazo, imprevisíveis que não podem ser interrompidas.
  * Testing the water: aplicativos sendo desenvolvidos ou testados no amazona EC2 pela primeira vez.

reservadas -> 1 a 3 anos, desconto de até 72% na cobrança por hora
  * uso previsível: aplicativos com estado estacionário ou uso previsível
  * requisitos específicos de capacidade: aplicativos que exigem capacidade reservada
  * pague adiantado: você pode fazer pagamentos adiantados para reduzir ainda mais os custos totais de computação
  * standard RIs: até 72% de desconto no preço sob demanda
  * convertible RIs: até 54% de desconto no preço sob demanda. Tem a opção de alterar para um tipo de RI diferente de valor igual ou superior
  * Scheduled RIs: inicie dentro da janela de tempo que você definir. Combine sua reserva de capacidade com uma programação recorrente previsível que requer
    apenas uma fração de dia, semana ou mês.

spot instance -> esquema de leilão, aws pode ou não aceitar a proposta, 90% de desconto, pode ser terminada a qualquer momento, usada para máquina de teste.
  * renderização de imagem, seguenciamento genômico, mecanismos de negociação algorítmicos.
  * usuários com necessidade de urgência de grandes quantidades de capacidade computacional adicional.
  * aplicativos com horários de inicio e termino flexíveis. 
  * aplicativos que só são viáveis com preços de computação muito baixos.

instância dedicada -> um servidor ec2 físico dedicado para seu uso. A opção mais cara.

hosts dedicados -> 
  * conformidade: requisitos regulatórios que podem não oferecer suporte à virtualização
  * licenciamento: ótimo para licenciamento que não suporta multilocação ou implantações em nuvem.
  * on-demand: pode ser adquirido sob demanda (por hora)
  * reserved: pode ser adquirido como reserva com até 70% de desconto no preço sob demanda
  * Dicas para prova: qualquer pergunta que fale sobre requisitos especiais de licenciamento
    Um host dedicado do amazona EC2 é um servidor físico com capacidade de instância do EC2 totalmente dedicada ao seu uso. Hosts dedicados permitem que
    você use licenças de software existentes por soquete, por núcleo ou por VM, incluindo Windows server, Microsoft SQL server e suse Linux enterprise 
    server.
saving plans com reserved instances ->
  * economize até 72%: todo o uso de computação da AWS, independentemente do tipo de instância ou região.
  * comprometa-se com 1 ou 3 anos: comprometa-se a usar uma quantidade específica de capacidade de computação (medida por hora) por um período de 1 ou 
    3 anos.
  * super flexível: não apenas ec2, isso também inclui tecnologias sem servidor como lambda ou fargate.

--------------------------------------------------
Recuperando metadados
curl -X PUT "http://169.254.169.254"

Dados de usuário VS. metadados
* Os dados do usuário são simplesmente scripts de bootstrap
* Metadados são dados sobre suas instâncias EC2
* você pode usar scripts de bootstrap (dados do usuário) para acessar metadados.

Qual comando na instância do EC2 para coletar os metadados do sistema?
  curl http://169.254.169.254/latest/meta-data/
--------------------------------------------------

INSTANCE LIFECYLE
o iam vai ter permitirar ou não permitir criar a instância

    iam ->  pending <-----------------
	        |                     |
rebooting <- running -> stopping -> stoped
	  ->    |                     |
            shutdown                  |
	        |                     |
	    terminated <--------------

stopping -> paga pelo ebs atrelado a instância, quando está em stopping, e vm é movida para outro host
	    ipv4 e ipv6 privado, você não perde eles, mas o ip público você perde

hibernating -> só para instância on-demand ou reservadas linux pode ir para o estado de hibernação
	       você paga pela memória ram e ebs

terminated -> neste estado só é possível voltar se tiver snapshot, o volume ebs é perdido

--------------------------------------------------

GRUPO DE POSICIONAMENTO / Placement groups

acionado nas opções avançadas no momento da criação da instância, pelo nome placemet group
têm 3 opções:

cluster -> 
  * Agrupamento de instâncias em uma única zona de disponibilidade. Recomendado para aplicativos que precisam de baixa latência de rede, alto rendimento
    de rede ou ambos.
  * somente determinados tipos de instância podem ser executadas em um grupo de posicionamento de cluster
        
disseminar/spread -> 
  * um grupo de posicionamento de propagação é um grupo de instâncias, cada uma colocada em hardware subjacente distinto.
  * Os spred placemente groups são recomendados para aplicativos que possuem um pequeno número de instâncias críticas que devem ser mantidas separadas
    umas das outras.
  * dicas para prova: usado para instâncias individuais

Partition/partição -> 
  * cada grupo de posicionamento de partição possui seu próprio conjunto de racks. Cada rack possui sua própria rede e fonte de alimentação. Não há duas
    partições em um grupo de posicionamento que compartilhem os mesmos racks, permitindo isolar o impacto de falhas de hardware em seu aplicativo.
  * EC2 divide cada grupo em segmentos lógicos chamados partições
  * dica para prova: usado para múltiplas instâncias EC2, HDFS, HBase, e Cassandra

DICAS: 
* Um grupo de posicionamento de cluster não pode abranger várias zonas de disponibilidade, enquanto um grupo de posicionamento partition podem.
* Somente determinados tipos de instâncias podem ser iniciadas em um grupo de posicionamento (otimizado para computação, otimizado para GPU, otimizado
  para memória, otimizado para armazenamento).
* A aws recomenda instâncias homogêneas em grupos de posicionamento de cluster
* não é possível mesclar grupos de posicionamentos
* você pode mover uma instância existente para um grupo de posicionamento. Antes de mover a instância, ela deverá estar no estado interrompido. Você pode
  mover ou remover uma instância usando a aws CLI ou um aws sdk, mas ainda não pode fazer isso por meio do console.

--------------------------------------------------

Networking com EC2
você pode anexar três tipos diferentes de placas de rede virtuais às suas instâncias do EC2

* ENI -> interface de rede elástica, para networking básico do dia a dia
  * simplesmente uma placa de rede virtual que permite: endereços IPv4 privados, endereços IPv4 público, endereço MAC, muitos endereços IPv6 e um ou mais
    grupos de segurança
  * casos de usos: crie uma rede de gestão, use dispositivos de rede e segurança em sua VPC, crie instâncias dual-homed com cargas de trabalho/funções em 
    subnets distintas, crie uma solução de baixo orçamento e alta disponibilidade.

* EN -> rede aprimorada/enhanced networkgin, usa virtualização de E/S de raiz única (SR-IOV) para fornecer alto desempenho
  * para redes de alto desempenho entre 10 Gbps - 100 Gbps
  * O SR-IOV fornece maior desempenho de E/S e menor utilização da CPU
  * desempenho: fornece maior largura de banda, maior desempenho de pacotes por segundo (PPS) e latências entre instâncias consistentemente mais baixas
  -> Dependendo do tipo de instância, a rede aprimorada pode ser habilitada usando:
      * adaptador de rede elástica (ENA): suporta velocidades de rede de até 100 Gbps para tipos de instância compatíveis.
      * interface de função virtual (VF) intel 82599: suporta velocidades de rede de até 10 Gbps para tipos de instância compatíveis. Normalmente usado
        em instâncias mais antigas.
      * Dicas para prova: Em qualquer cenário, escolha ENA em vez de interface VF

* EFA -> adaptador de tecido elástico, acelera aplicativos de computação de alto desempenho (HPC) e aprendizado de máquina
  * Um dispositivo de rede que você pode conectar a sua instância do amazona EC2 para acelerar aplicações de computação de alto desempenho (HPC) e machine
    learning.
  * Fornece latência mais baixa e mais consistente e maior rendimento do que o transporte TCP tradicionalmente usado em sistemas HPC baseados em nuvem.
  * EFA pode usar OS-BYPASS: isso torna tudo muito mais rápido com latência muito menor, o OS-BYPASS permite que aplicativos de HPC e de aprendizado de 
    máquina ignorem o kernel do sistema operacional e se comuniquem diretamente com o dispositivo EFA. Atualmente não é compatível com Windows, apenas linux

==================================================================================

VPC

ordem:
Região -> vpc -> az -> subnets
lembrando, dentro de uma região tem mais de uma AZ
pode se ter várias vpcs na região (5 por região)

vpc -> sistema lógico virtual criado para isolar conteúdo dentro da mesma região, uma vpc não pode participar de duas regiões ao mesmo tempo
subnets são criadas para segmentar/separar conteúdos dentro de uma vpc

dentro de uma vpc sempre tem um roteador, não é visivel para gente, serviço atribuido é a (tabela de roteamento == routing table), essa tabela consegue enxergar todas as redes no caso as subnets, e com isso podemos conversar de subnet para subnet.
	A subnet sendo pública, temos também a rota para internet 0.0.0.0/0, neste caso o roteador acessa o internet gateway e assim sai para internet

PARA TORNAR UMA SUBNET/SUBREDE PÚBLICA -> ações -> editar configurações de sub-rede -> habilitar endereço IPV4 público de atribuições automática -> salvar

ligar vpc ao internet gateway -> internet gateway -> ações -> associar vpc -> escolha sua vpc -> associar gateway

--------------------------------------------------
Internet gateway (IGW)
* permite que recursos na vpc conecte na internet, exemplo: EC2
* é dimensionado horizontalmente e é altamente disponível e redundante
* Deve ser criado separadamente de uma vpc
* um vpc pode somente ser anexado a um IGW e vice versa
* O internet gateway por si só não permitem acesso a internet
* as tabelas de rotas também devem ser editadas

--------------------------------------------------
NAT GATEWAY
* NAT gerenciado pela aws, maior largura de banda, alta disponibilidade, sem administração 
* pague por hora pelo uso e largura de banda
* o nat gateway é criado em uma zona de disponibilidade especifica, usa um elastic IP
* não pode ser usado pela instância EC2 na mesma sub-rede (somente de outras sub-redes)
* requer um IGW (sub-rede privada => NATGW => IGW)
* 5 GBps de largura de banda com escalonamento automático até 100 GBps
* nenhum grupo de segurança para gerenciar/necessário
* não usa bastion host

==================================================================================
aws transit gateway

* O AWS Transit Gateway conecta VPCs e redes locais por meio de um hub central. Com o AWS Transit Gateway, você pode adicionar rapidamente Amazon VPCs, contas da AWS, capacidade de VPN ou gateways do AWS Direct Connect para atender a uma demanda inesperada, sem ter que lidar com conexões complexas ou tabelas de roteamento massivas. Esta é a solução operacionalmente menos complexa e também econômica.
* Isso simplifica a sua rede e põe fim a relações de peering complexas. Ele atua como um roteador de nuvem - cada nova conexão é feita apenas uma vez

* permite que você tenha peering transitivo entre milhares de VPCs e data centers locais
* funciona em um modelo hub-and-spoke
* funciona regionalmente, mas você pode implementá-lo em várias regiões
* você pode usá-lo em várias contas aws usando RAM (Resource access manager)

dica para o exame:
* você pode usar tabelas de rotas para limitar como as VPCs se comunicam entre si
* funciona com direct connect e também com conexões VPN
* suporta multicast IP (não compatível com nehum outro serviço aws)

pergunta sobre como simplificar sua topologia de rede, pense em usar transit gateway

==================================================================================
stateful
	cria regra de entrada ele já tem regra de saida
	security group aplicado as instâncias


stateless
	cria regra de entrada e tem de criar regra de saida
	network acl aplicado na subnet 



VPC Peering -> comunicação entre duas vpcs


==================================================================================
VPC ENDPOINT

* Interface endpoint (desenvolvidos por privateLink):
	para acessar esses serviços privados da sua ec2, terá de criar um ENI - elastic network interface 
        exemplo serviços privados: cloud formation, codeplay, private link

  * Fornece um ENI(endereço IP privado) como ponto de entrada (deve anexar um grupo de segurança)
  * Suporta a maioria dos serviços AWS
  * $ por hora + $ por GB de dados processados

* Gateway endpoint (public):
	para acessar esses serviços públicos, terá de criar gateway endpoint
        exemplo serviços públicos: s3 ou DynamoDB
  * Provisiona um gateway e deve ser usado como destino em uma tabela de rotas (não usa security groups)
  * Suporta s3 e DynamoDB
  * FREE 

* GATEWAY OU INTERFACE ENDPOINT FOR S3 ?
  * O gateway provalvelmente será o preferido o tempo todo no exame
  * Custo: gratuito para gateway e pago para interface endpoint
  * O acesso preferencial do interface endpoint é em on-premises (SITE TO SITE VPN OR DIRECT CONNECT), em uma vpc diferente ou em uma região diferente

--------------------------------------------------
Network Acl
* NACL é como um firewall que controla o tráfego para as subnetes
* default network ACL: sua vpc vem automaticamente com uma ACL de rede padrão e, por padrão, permite todo o tráfego de entrada e saída.
* custom network ACL: você pode criar ACLs de rede personalizadas. Por padrão, cada ACL de rede personalizada nega todo o tráfego de entrada e saída 
  até que você adicione regras.
* subnet associations: cada subnet em sua VPC deve estar associada a uma ACL de rede. Se você não associar explicitamente uma subnet a uma ACL de rede, 
  a subnet será automaticamente associada a ACL de rede padrão.
* Boquear endereços IP: bloqueie endereços IP usando ACLs de rede, não security groups

* você pode associar uma network ACL a diversas subnets, entretando, uma subnet pode ser assiciada a apenas 1 ACL de rede por vez. Ao associar uma network 
  ACL a uma subnet, a associação anterior é removida.
* As ACLs de rede contêm uma lista numerada de regras que são avaliadas em ordem, começando pela regra de número mais baixo.
* As ACLs de rede têm regras de entrada e saída separadas, e cada regra pode permitir ou negar tráfego
* As ACLs de rede não têm estado, as respostas ao tráfego de entrada permitido estão sujeitas às regras do tráfego de saída (e vice versa)
--------------------------------------------------
VPC Peering

* permite conectar 1 VPC a outro por meio de uma rota de rede direta usando endereços IP privados
* as instâncias se comportam como se estivessem na mesma rede privada
* você pode emparelhar VPCs com outras contas da aws, bem como  com outras VPCs na mesma conta
* o peerging está em uma configuração em estrela (por exemplo, 1 vpc central emparelha com 4 outros) sem peerging transitivo
* você pode fazer peerging entre regiões
* sem intervalos de endereços CIDR sobrepostos

--------------------------------------------------

PrivateLink
* a melhor maneira de expor uma VPC de serviço a dezenas, centenas ou milhares de VPCs de clientes
* não requer peering de VPC, sem tabelas de rotas, NAT gateways, internet gateways, etc.
* requer um network load balancer na vpc de serviço e uma ENI na vpc do cliente
* se você vir uma pergunta sobre peerging de VPCs para dezenas, centenas ou milhares de VPCs de clientes, pense no aws privatelink

--------------------------------------------------

VPN cloudHub
se você tiver vários sites, cada um com sua própria conexão vpn, poderá usar o Aws vpn cloudHub para conectar esses sites.
* modelo hub-and-spoke
* baixo custo e fácil de gerenciar
* ele opera na internet pública, mas todo o tráfego entre o gateway do cliente e o aws vpn cloudhub é criptografado
DICA: como você pode simplificar sua topologia de rede VPN ? pense em VPN Hub

--------------------------------------------------
Direct Connect
* usando o aws direct connect, você pode estabelecer conectividade privada entre a aws e seu data center ou escritório.
* em muitos casos, você pode reduzir os custos de rede, aumentar o rendimento da largura de banda e fornecer uma experiência de rede mais consistente do que conexões baseadas na internet.

2 tipos de direct  connect connection
* conexão dedicada: uma conexão ethernet física associada a um único cliente. Os clientes podem solicitar uma conexão dedicada por meio do console do aws      direct connect, da cli ou api.

* conexão hospedada: uma conexão ethernet física que um parceiro da aws direct connect provisiona em nome de um cliente. Os clientes solicitam uma conexão hospedada entrando em contato com um parceiro do aws direct connect partner program, que provisiona a conexão.

VPNs vs direct connect
as vpns permitem a comunicação privada, mas ainda atravessam a internet pública para que os dados sejam entregues. Embora seguro, pode ser dolorosamente lento.

direct connect é: rápido, seguro, confiável e capaz de obter um rendimento massivo
DICA: vpn caindo e precisa reduzir custos de rede, aumentar o rendimento da sua rede é direct connect

==================================================================================
ESCALABILIDADE E ALTA DISPONIBILIDADE
* Escalabilidade significa que uma aplicação/sistema pode lidar com cargas maiores através da adaptação.
* Existem dois tipos de escalabilidade:
  * Escalabilidade vertical
  * Escalabilidade horizontal(=elasticidade)
* A escalabilidade está vinculada, mas é diferente da alta disponibilidade

ESCALABILIDADE VERTICAL
* Escalabilidade vertical significa aumentar o tamanho da instancia
* Por exemplo, seu aplicativo é executado em um t2.micro
* Dimensionar esse aplicativo verticalmente significa executá-lo em um t2.large
* A escalabilidade vertical é muito comum em sistemas não distribuídos, como banco de dados.
* RDS e ElastiCache são serviços que podem ser dimensionados verticalmente
* Geralmente há um limite para quanto você pode escalar verticalmente (limite de hardware)

ESCALABILIDADE HORIZONTAL
* Escalabilidade horizontal significa aumentar o número de instâncias/sistemas para sua aplicação
* A escala horizontal implica sistemas distribuídos.
* Isso é muito comum em aplicações web/aplicações modernas
* É fácil escalar horizontalmente graças as ofertas de nuvem, como Amazon EC2

ALTA DISPONIBILIDADE
* Alta disponibilidade geralmente anda de mãos dadas com escalabilidade horizontal
* Alta disponibilidade significa executar seu aplicativo/sistema em pelo menos 2 data centers(==zonas de disponibilidade)
* O objetivo da alta disponibilidade é sobreviver a perda do data center
* A alta disponibilidade pode ser passiva (para RDS Multi AZ, por exemplo)
* A alta disponibilidade pode estar ativa (para escalabilidade horizontal)

Alta disponibilidade e escalabilidade para EC2
* Dimensionamento vertical: aumentar o tamanho da instância(=aumentar/diminuir)
  * De t2.nano - 0.5G de ram, 1vCPU
  * Para u-12tbl.metal - 12.3 TB of ram, 448 vCPUs
* Dimensionamento horizontal: aumenta o número de instâncias (=expansão/aumento horizontal)
  * Grupo de auto scaling
  * load balancer

* Alta disponibilidade: execute instâncias para o mesmo aplicativo em várias AZs
  * auto scaling group multi AZ
  * load balancer multi AZ 

LOAD BALANCER
* distribua a carga entre várias instâncias downstream
* expor um único ponto de acesso (DNS) ao seu aplicativo
* lidar perfeitamente com falhas de instâncias downstream
* faça verificações de integridade regulares em suas instâncias
* forneça terminação SSL (HTTPS) para seus sites
* imponha a aderência com cookies
* alta disponibilidade entre zonas
* separar o tráfego público do tráfego privado
* Está integrado com muitas ofertas/serviços da AWS
  * ec2, grupos de auto scaling ec2, amazon ecs
  * aws certificate manager (ACM), cloud watch
  * route 53, aws awf, aws global accelerator

TIPOS DE BALANCEADORES DE CARGA
* A aws tem quatro tipos de balanceadores de carga gerenciados
* classic load balancer(v1 - geração antiga) - 2009 -CLB
  * HTTP, HTTPS, TCP, SSL (secure TCP)
* Application load balancer(v2 - nova geração) - 2016 - ALB
  * HTTP, HTTPS, WEBSOCKET
* Network load balancer(v2 - nova geração) - 2017 - NLB
  * TCP, TLS (SECURE TCP), UDP
* Gateway Load Balancer - 2020 - GWLB
  * Opera na camada 3 (camada de rede) - protocolo IP 
* Alguns balanceadores de carga podem ser configurados como ELBs internos (privados) ou externos (públicos)

Aplication Load Balancer/ALB(v2)
(detalhado e inteligente)
* Application load balancer atua na camada 7(http)
* Balanceamento de carga para vários aplicativos HTTP em máquinas (grupo alvo)
* Balanceamento de carga para vários aplicativos na mesma máquina (ex.: contêineres)
* suporte para http/2 e websocket
* suporte a direcionamentos (de http para https, por exemplo)
* são ideais para microsserviços e aplicativos baseados em contêiner (ex.: docker e amazon ecs)

GRUPOS DE DESTINO DO APPLICATION LOAD BALANCER(V2)
* instâncias ec2 (podem ser gerenciadas por um grupo de auto scaling) - http
* tarefas do ecs (gerenciadas pelo próprio ecs) - http
* funções lambda - a solicitação http é traduzida em um evento JSON
* endereço IP - devem ser IPs privados
* o alb pode rotear para vários grupos-alvo
* os health checks são realizados no nível do grupo alvo


* routing -> path-based
	  -> host-based
apontar -> instância
	-> ip address
	-> lambda
	-> containers
	-> target
----------------------------------------------------------
Network load balancer/NLB
* Balanceadores de carga de rede(camada 4) permitem:
  * encaminhar tráfego TCP e UDP para suas instâncias
  * lidar com milhões de solicitações por segundo
  * menos latência ~ 100 ms (vs 400 ms para ALB)
* O NLB tem um IP estático por AZ e oferece suporte à atribuição de IP elástico (útil para colocar IP específico na lista de permissãoes)
* NLB são usados para desempenho extremo, tráfego TCP ou UDP
 * não inclui no nível gratuito da AWS

* Network load balancer - Target groups
 * instâncias EC2
 * endereços IP - deve ser IPs privados
 * Application load balancer
 * as verificações de integridade suportam os protocolos TCP, HTTP e HTTPS

----------------------------------------------------------
Gateway Load Balancer
 * deploy, dimensione e gerencie uma frota de dispositivos virtuais de rede de terceiros na AWS
 * Exemplo: Firewalls, sistemas de detecção e prevenção de intrusões, sistemas de inspeção profunda de pacotes, manipulação de carga util.
* Opera na camada 3 (camada de rede) - pacotes de IP
* Combina as seguintes funções:
 * gateway de rede transparente - entrada/saida única para todo tráfego
 * load balancer - distribui tráfego para seus dispositivos virtuais
* Usa o protocolo GENEVE na porta 6081

* Gateway load balancer - Target groups
 * instâncias EC2
 * endereços IP - deve ser IPs privados

----------------------------------------------------------
SSL/TLS - Basic
* Um certificado SSL permite que o tráfego entre seus clientes e seu balanceador de carga seja criptografado em trânsito (criptografia em trânsito)
* SSL refere-se secure sockets layer, usado para criptografar conexões 
* TLS refere-se ao transport layer security, que é uma versão mais recente
* Hoje em dia, os certificados TLS são usados principalmente, mas as pessoas ainda se referen como SSL
* Certificados SSL públicos são emitidos por autoridades de certificação (CA)
* COMODO, SYmantec, GoDaddy, gloablsign, digicert, letsencrypt, etc
* os certificados SSL têm uma data de validade (você define) e devem ser renovados

Load Balancer - SSL Certificates
* O balanceador de carga usa um certificado x.509 (certificado de servidor SSL/TLS)
* você pode gerenciar certificados usando ACM (AWS certificate manager)
* você pode criar e carregar seus próprios certificados como alternativa
* HTTPS listener:
 * você deve especificar um certificado padrão
 * você pode adicionar uma lista opcional de certificados para oferecer suporte a vários domínios
 * os clientes podem usar SNI (server name indication) para especificar o nome do host que alcançam
 * capacidade de especificar uma política de segurança para suportar versões mais antigas de SSL/TLS (clientes legados)

SSL - Server Name Indication (SNI)
* SNI resolve o problema de carregar vários certificados SSL em um servidor web (para servir vários sites)
* é um protocolo "mais recente" e exige que o cliente indique o nome do host do servidor de destino no handshake SSL inicial
* O servidor encontrará então o certificado correto ou retornará o padrão

Observação:
* funciona apenas para ALB e NLB (geração mais recente), cloudFront
* não funciona para CLB (geração mais antiga)

Elastic Load Balancer - SSL Certificates
* Classic Load Balancer (v1)
 * suporta apenas um certificado SSL
 * deve usar vários CLB para vários nomes de host com vários certificados SSL

* Application Load Balancer (v2)
 * suporta vários ouvintes com vários certificados SSL
 * usa indicação de nome de servidor (SNI) para fazê-lo funcionar

* Network Load Balancer (v2)
 * Suporta vários ouvintes com vários certificados SSL
 * usa indicação de nome de servidor (SNI) para fazê-lo funcionar

----------------------------------------------------------
Auto Scaling Group
* Na vida real, a carga nos seus sites e aplicativos pode mudar
* Na nuvem, você pode criar e se livrar de servidores muito rapidamente

* O objetivo de um auto scaling group (ASG) é:
 * expandir horizontalmente (adicionar instâncias do EC2) para corresponder a um aumento de carga
 * Aumentar a escala (remover instâncias do EC2) para corresponder a uma carga reduzida
 * Garantir que tenhamos um número mínimo e máximo de instâncias do EC2 em execução
 * Registrar automaticamente novas instâncias em um balanceador de carga
 * Recrie uma instância EC2 caso uma anterior seja encerrada (ex.: se não estiver íntegra)

* ASG são gratuitos (você paga apenas pelas instâncias EC2 subjacentes)

CloudWatch Alarms & Scaling
* É possível escalar um ASG com base em alarmes do cloudWatch
* Um alarme monitora um métrica (como média de CPU ou uma métrica personalizada)
* Métricas como média de CPU são calculadas para todas as instâncias ASG
* Com base no alarme:
 * podemos criar políticas de expansão (aumentar o número de instâncias)
 * podemos criar políticas de escala (diminuir o número de instâncias)

==================================================================================

AWS DATABASES
Relacional -> multi-az -> para desastres, se eu perder uma database a outra sobe, DNS único
	      read replica -> copia a database atual para outra database, feita de forma manual, tem dois DNS, para ter read replica tem que ter backup ativo

Não relacional -> 


databases suportadas pela aws -> amazon aurora, mysql, mariadb, postgresql, oracle, microsoft sql server

BACKUPS
Automated 1 - 35 dias (1 sec) -> s3 (free)
Db snapshot -> manual (auto)

----------------------------------------------------------
***Amazon RDS overview***
* RDS significa serviço de banco de dados relacional
* É um serviço de banco de dados gerenciado que usa sql como linguagem de consulta
* Permite criar banco de dados na nuvem gerenciados pela AWS
 * Postgres
 * Mysql
 * MariaDb
 * Oracle
 * Microsoft SQL server
 * IBM DB2
 * Aurora (banco de dados proprietário da aws)

* Vantagem em usar RDS vs  deploy de banco de dados na EC2
* RDS é um serviço gerenciado:
 * provisionamento automatizado, aplicação de patches no sistema operacional
 * Backups contínuos e restore de data/hora específico(Restauração point in time)
 * dashboards monitoring
 * read replicas para melhor desempenho de leitura
 * Configuração multi AZ para DR(disaster recovery/recuperação de desastres)
 * Janelas de manutenção para atualizações
 * Capacidade de escala (vertical e horizontal)
 * armazenamento apoiado por EBS (gp2 ou io1)
* Mas você não pode usar SSH em suas instâncias

RDS - storage auto scaling
* Ajuda a aumentar dinamicamente o armazenamento na sua instância de banco de dados RDS
* quando o RDS detecta que você está ficando sem armazenamento livre no banco de dados, ele é dimensionado automaticamente
* evite dimensionar manualmente o armazenamento do seu banco de dados
* você deve definir o limite máximo de armazenamento (limite para o armazenamento de banco de dados)
* modificar automaticamente o armazenamento se:
 * o armazenamento gratuito é inferior a 10% do armazenamento alocado
 * o armazenamento baixo dura pelo menos 5 minutos
 * 6 horas se passaram desde a última modificação
* útil para aplicativos com cargas de trabalho imprevisíveis
* suporta todos os mecanismos de banco de dados RDS

RDS read replicas para escalabilidade de leitura
* até 15 replicas de leitura
* dentro de AZ, entre AZ ou entre regiões
* a replicação é ASYNC, portanto as leituras são eventualmente consistentes
* as réplicas podem ser promovidas para seu próprio banco de dados
* os aplicativos devem atualizar a cadeia de conexão para aproveitar réplicas de leitura

RDS read replicas - casos de uso
* você tem um banco de dados de produção que está assumindo carga normal
* você deseja executar um aplicativo de relatórios para executar algumas análises
* você cria uma réplica de leitura para executar a nova carga de trabalho lá
* o aplicativo de produção não é afetado
* replicas de leitura são usadas para select (=read) não é usado para (insert, update, delete)

RDS read replicas - custo de rede
* na aws há um custo de rede quando os dados vão de uma az para outra
* para réplicas de leitura RDS na mesma região, você não paga essa taxa
* para réplicas de leitura RDS em outra região, você paga taxa

RDS multi AZ (recuperação de desastres) não é para desempenho
* replicação SYNC
* um nome DNS - failover automático do aplicativo para modo de espera
* aumentar a disponibilidade
* failover em caso de perda de AZ, perda de rede, instância ou falha de armazenamento
* nenhuma intervenção manual em aplicativos
* não usado para dimensionamento

* observação: as réplicas de leitura devem ser configuradas como multi az para recuperação de desastres (DR)

RDS single AZ a Multi AZ
* operação com tempo de inatividade zero (sem necessidade de parar o banco de dados)
* basta clicar em "modificar" para o banco de dados
* o seguinte acontece internamente:
 * um snapshot é tirado
 * um novo banco de dados é restaurado a partir do snapshot em uma nova AZ
 * sincronização é estabelecida entre os dois bancos de dados

----------------------------------------------------------
***Dynamo DB***
serviço -> nosql
milisegundos (baixa latência)
documentos -> key value -> chave:valor
quando utilizar -> app web/mobile
		   games

armazenamento feito em ssd
3 data centers
consistent reads > 1 segundo
strongly consitent reads < 1 segundo

* O amazona dynamoDB é um serviço de banco de dados NoSQL rápido e flexível para todas as aplicações que precisam de latência consistente de milissegundos
  de um digito em qualquer escala
* é um banco de dados totalmente gerenciado e oferece suporte a modelos de dados de documentos e chave-valor
* seu modelo de dados flexível e desempenho confiável o tornam ideal pra dispositivos móveis, web, jogos, tecnologia de publicidade, IoT e muitos outros
  aplicativos.

4 fatos sobre o dynamoDB
* armazenamento em SSD
* distriuidos por 3 data centers geograficamente distintos
* leituras eventualmente consistentes (padrão)
* leituras fortemente consistentes 

qual a diferença entre leituras eventualmente consistentes e leituras fortemente consistentes ?
* Eventualmente: a consistência em todas as cópias de dados geralmente é alcançada em um segundo. Repetir uma leitura após um curto período de tempo deve
   retornar os dados atualizados. Melhor desempenho de leitura.
* Fortemente: uma leitura fortemente consistente retorna um resultado que reflete todas as gravações que recebem uma resposta bem-sucedida antes da leitura

DynamoDB accelerator (DAX)
* cache na memória totalmente gerenciado e altamente disponível
* melhoria de desempenho de 10x
* reduz o tempo de solicitação de milissegundos para microssegundos, mesmo sob carga
* não há necessidade de os desenvolvedores gerenciarem a lógica de cache
* compatível com chamadas de API do dynamoDB

Capacidade sob demanda
* preços de pagamento por solicitação
* equilibrar custo e desempenho
* sem capacidade mínima 
* pague mais por solicitações do que com capacidade provisionada
* use para lançamentos de novos produtos

DynamoDB – Processamento de Streams
• Fluxo ordenado de modificações a nível de item (criação/atualização/exclusão) em uma tabela.
• Casos de uso:
• Reagir a mudanças em tempo real (e.g., envio de e-mails de boas-vindas a novos usuários).
• Análises de uso em tempo real.
• Inserir dados em tabelas derivadas.
• Implementar replicação entre regiões.
• Invocar AWS Lambda em alterações na sua tabela DynamoDB.

DynamoDB Streams
• Retenção de 24 horas.
• Número limitado de consumidores.
• Processamento usando AWS Lambda Triggers ou o adaptador DynamoDB Stream Kinesis.

Kinesis Data Streams (mais recente)
• Retenção de 1 ano.
• Alto número de consumidores.
• Processamento usando AWS Lambda, Kinesis Data Analytics, Kinesis Data Firehose, AWS Glue Streaming ETL, entre outros.

==================================================================================

Segurança

Criptogrfia do lado do servidor em repouso:
 * os dados são criptografados após serem recebidos pelo servidor
 * os dados são descriptografados antes de serem enviados
 * é armazenado de forma criptografada graças a uma chave (geralmente uma chave de dados)
 * As chaves de criptografia/descriptografia devem ser gerenciadas em algum lugar, e o servidor deve ter acesso a elas
  
Criptografia do lado do cliente
 * os dados são criptografados pelo cliente e nunca descriptografados pelo servidor
 * os dados serão descriptografados por um cliente receptor
 * o servidor não deve ser capaz de descriptografar os dados
 * poderia aproveitar a criptografia de envelope

AWS KMS (Key Management Service)
 * sempre que você ouve "criptografia" para um serviço AWS, provavelmente é KMS
 * A aws gerencia chaves de criptografia para nós
 * totalmente integrado com IAM para autorização
 * maneira fácil de controlar o acesso aos seus dados
 * capaz de auditar o uso de chaves KMS usando o cloud Trail
 * integrado perfeitamente a maioria dos serviços da AWS (EBS, S3, RDS, SSM...)
 * Nunca armazene seus segredos em texto simples, especialmente em seu código!
  * criptografia de chave KMS também disponível por meio de chamadas de API (SDK, CLI)
  * Segredos criptografados podem ser armazenados no código/variáveis de ambiente

Tipos de chaves KMS
* Kms Keys é o novo nome da KMS customer master key

* simétrico (chaves AES-256)
 * chave de criptografia única usada para criptografar e descriptografar
 * os serviços da aws integrados ao KMS usam CMKs simétricos
 * você nunca obtém acesso a chave KMS sem criptografia (deve chamar a API KMS para usar)

* Assimétrico (pares de chaves RSA e ECC)
 * par de chaves pública (criptografar) e privada (descriptografar)
 * usado para operações de criptografar/descriptografar ou assinar/verificar
 * a chave pública pode ser baixada, mas você não pode acessar a chave privada sem criptografia
 * caso de uso: criptografia fora da aws por usuários que não podem chamar a API do KMS

* chaves de propriedade da AWS (gratis): SSE-S3, SSE-SQS, SSE-DDB (chave padrão)
* chaves gerenciadas pela aws: grátis (aws/nome-do-serviço, exemplo: aws/rds ou aws/ebs)
* chaves gerenciadas pelo cliente criadoa no KMS: US$ 1/mês
* chaves gerenciadas pelo cliente importadas: US$ 1/mês
* + pagar por chamadas de API para KMS (US$ 0,03 / 10.000 chamadas)

* Rotação automática de chaves:
 * chave KMS gerenciada pela AWS: automática a cada 1 ano
 * chave KMS gerenciada pelo cliente: (deve ser habilitada) automática e sob demanda
 * chave KMS importada: somente rotação manual possível usando alias

Copiando snapshots entre contas
1 - crie um snapshot, criptografado com sua própria chave kms (chave gerenciada pelo cliente)
2 - anexe uma politica de chave kms para autorizar o acesso entre contas
3 - compartilhe o snapshot criptografado
4 - no destino, crie uma cópia do snapshot, criptografe-o com uma CMK em sua conta
5 - crie um volume a partir do snapshot

AWS Secret Manager
 * serviço mais recente, destinado a armazenar segredos
 * capacidade de forçar a rotação de segredos a cada X dias
 * automatizar a geração de segredos em rotação (usa lambda)
 * integração com amazona RDS (mysql, PostgreSQL, aurora)
 * os segredos são criptografados usando KMS
 * Principalmente destinado a integração RDS

Secret Manager - Multi-Region Secrets
 * Replique segredos em várias regiões da aws
 * o secrets manager mantém as replicas de leitura sincronizadas com o secret primário
 * capacidade de promover uma réplica de leitura para um secreta independente
 * casos de uso: aplicativos multirregionais, estratégias de recuperação de desastres, banco de dados multirregionais.

AWS Certificate Manager (ACM)
 * provisione, gerencie e implante certificados TLS facilmente
 * fornecer criptografia em voo para sites (HTTPS)
 * suporta certificados TLS públicos e privados
 * gratuito para certificados TLS públicos
 * Renovação automática do certificado TLS
 * Integrações com (carregar certificados TLS em)
  * balanceadores de carga elásticos (CLB, ALB, NLB)
  * distribuições cloudFront
  * APIs no API gateway
 * não é possível usar ACM com EC2 (não pode ser extraído)

AWS AWF - Web Application Firewall
 * serve para bloquear scripts cross-site e ataques de injeção de SQL.
 * protege seus aplicativos da web contra explorações comuns da web (camada 7)
 * a camada 7 é HTTP (vs. a camada 4 é tcp/udp)
 * Deploy em
  * application load balancer
  * API gateway
  * cloudFront
  * appSync graphQL API
  * cognito user pool
 
 * Definir regras ACL (web access control list):
  * conjunto de IP: até 10.000 endereços Ip - use várias regras para mais IPs
  * HTTP headers, HTTP body, string url protege contra ataques comuns - sql injection e cross-site scripting (XSS) 
  * restrições de tamanho, correspondência geográfica (bloqueio paises)
  * regras baseadas em taxas (para contar ocorrências de eventos) - para proteção DDoS
 * ACL da web são regionais, exceto para cloudFront
 * um grupo de regras é um conjunto reutilizável de regras que você pode adicionar a uma ACL da web
 * WAF - IP fixo ao usar WAF com um load balancer 
  * o waf não oferece suporte ao network load balancer (camada 4)
  * podemos usar o global accelerator para IP fixo e waf no ALB

AWS Shield: proteja-se contra ataques DDoS
 * DDoS: Distributed Denial of servisse - muitas solicitações ao mesmo tempo
 * Padrão AWS Shield:
  * serviço gratuito que é ativado para todos os clientes da aws
  * fornece proteção contra ataques como SYN/UDP floods, ataques de reflexão e outros ataques de camada 3/camada 4
 * AWS Shield Advanced: 
  * serviço opcional de mitigação de DDoS (US$ 3000 por mês por organização)
  * proteja-se contra ataques mais sofisticados no amazona EC2, elastic load balancing (ELB), cloudFront, aws global accelerator e route53
  * acesso 24 horas por dia, 7 dias por semana a equipe de resposta a DDoS da aws (DRP)
  * proteja-se contra taxas mais altas durante picos de uso devido a DDoS
  * a camada de aplicação automática shield advanced cria automaticamente uma mitigação de DDoS, avalia e implementa regras do aws waf para mitigar
    ataques de camada 7

AWS Firewall Manager
 * gerenciar regras em todas as contas de uma organização aws
 * politica de segurança: conjunto comum de regras  de segurança
  * regras waf (application load balancer, api gateways, cloudFront)
  * aws shield advanced(ALB, CLB, NLB, elastic ip, cloudFront)
  * grupos de segurança para recursos ec2, application load balancer e ENI em vpc
  * firewall de rede aws (nível vpc)
  * firewall dns do amazona route53 resolver
  * as politicas são criadas a nível regional
 * as regras são aplicadas a novos recursos a medida que são criados (bom para conformidade) em todas as contas futuras da sua organização

WAF vs Firewall manager vs shield
 * waf, shield e firewall manager são usados juntos para proteção abrangente
 * defina suas regras de ACL da web no waf
 * para proteção granular de seus recursos, o waf sozinho é a escolha correta
 * se você deseja usar o waf em todas as contas, acelerar a configuração do waf, automatizar a proteção de novos recursos, usar o firewall manager com o waf
 * o shield advanced adiciona recursos adicionais ao awf, como dedicado suporte da shield response team (SRT) e relatórios avançados
 * se você é propenso a ataques DDoS frequentes, considere comprar o shield advanced

Amazon GuardDuty
* Descoberta inteligente de ameaças para proteger sua conta AWS
* utiliza algoritmos de machine learning, detecção de anomalias, dados de terceiros
* um clique para habilitar (teste de 30 dias), sem necessidade de instalar software
* os dados de entrada incluem:
 * cloudTrail Events logs - registra chamadas de api incomuns, implantações não autorizadas
  * cloudTrail management events - cria VPC subnet, cria trail
  * cloudTrail S3 data events - obter objeto, listar objetos, excluir objeto
 * VPC flow logs - tráfego interno incomum, endereço ip incomum
 * DNS LOGS - instancias ec2 comprometidas enviando dados codificados em consultas DNS
 * Optional feature - logs de autoria eks, rds e aurora, ebs, lambda eventos de dados s3
* pode configurar regras do eventbridge para ser notificado em caso de descobertas
* as regras do eventbridge podem ter como alvo aws lambda ou sns
* pode proteger contra ataques de criptomoeda (tem uma descoberta para isso)

Amazon Inspector
• Avaliações de Segurança Automatizadas

• Para instâncias EC2
 • Aproveitando o agente AWS System Manager (SSM)
 • Analisar contra acessibilidade de rede não intencional
 • Analisar o sistema operacional em execução contra vulnerabilidades conhecidas

• Para Imagens de Contêiner enviadas para o Amazon ECR
 • Avaliação das Imagens de Contêiner à medida que são enviadas

• Para Funções Lambda
 • Identifica vulnerabilidades de software no código da função e nas dependências do pacote
 • Avaliação das funções à medida que são implantadas

• Relatórios e integração com o AWS Security Hub
• Enviar descobertas para o Amazon EventBridge

O que o Amazon Inspector avalia?
• Lembre-se: apenas para instâncias EC2, Imagens de Contêiner e funções Lambda
• Varredura contínua da infraestrutura, somente quando necessário
• Vulnerabilidades de pacotes (EC2, ECR e Lambda) – banco de dados de CVE
• Alcance de rede (EC2)
• Uma pontuação de risco é associada a todas as vulnerabilidades para priorização

AWS Macie
• O Amazon Macie é um serviço totalmente gerenciado de segurança e privacidade de dados que usa aprendizado de máquina e correspondência de padrões para descobrir e proteger seus dados sensíveis na AWS.
• O Macie ajuda a identificar e alertar sobre dados sensíveis, como informações de identificação pessoal (PII).

O Amazon Macie é um serviço de segurança de dados totalmente gerenciado que usa Machine Learning para descobrir e proteger seus dados confidenciais armazenados em buckets S3. Ele fornece automaticamente um inventário de buckets S3, incluindo uma lista de buckets não criptografados, buckets acessíveis publicamente e buckets compartilhados com outras contas AWS. Ele permite que você identifique e alerte você sobre dados confidenciais, como Informações de Identificação Pessoal (PII).
----------------------------------------------------------

***Elasticache***
serviço -> fast (criação, operação, escalabilidade)
não usa discos, usa in-memory cache, armazena em memória

tipos:
memorycached -> objetos
redis -> key-value e só o redis trabalha com multi-az

----------------------------------------------------------

***Redshift***

Visão Geral do Amazon Redshift 
- O Redshift é baseado no PostgreSQL, mas não é usado para OLTP.
- É um banco de dados OLAP (Online Analytical Processing) voltado para análises e data warehousing.
- Desempenho 10x superior a outros data warehouses, podendo escalar para petabytes de dados.
- Armazena os dados em formato colunar (em vez de baseado em linhas) e possui um motor de consultas paralelas.
- Oferece dois modos:
  - Cluster Provisionado
  - Cluster Serverless
- Possui uma interface SQL para execução de consultas.
- Ferramentas de BI como Amazon QuickSight e Tableau podem ser integradas.
- Comparação com Athena:
  - Redshift é mais rápido para consultas complexas, joins e agregações, graças ao uso de índices.

Redshift Cluster 
- Nó líder (Leader Node): Responsável pelo planejamento das consultas e agregação dos resultados.
- Nó de computação (Compute Node): Executa as consultas e envia os resultados para o nó líder.
Modo Provisionado:
 - Permite escolher os tipos de instância antecipadamente.
 - Possibilidade de reservar instâncias para economia de custos.


Redshift – Snapshots & Recuperação de Desastres (DR)
- O Redshift possui o modo Multi-AZ para alguns clusters.
- Snapshots são backups pontuais de um cluster, armazenados internamente no S3.
- Os snapshots são incrementais (somente as alterações são salvas).
- É possível restaurar um snapshot em um novo cluster.
- Tipos de Snapshots:
 - Automáticos:
   - Criados a cada 8 horas, a cada 5 GB de alterações ou conforme um agendamento.
   - O tempo de retenção pode ser definido entre 1 a 35 dias.
 - Manuais:
   - Retidos até serem excluídos manualmente.
- O Amazon Redshift pode ser configurado para copiar snapshots automaticamente (automáticos ou manuais) para outra Região da AWS.

Redshift Spectrum 
- Permite consultar dados diretamente no S3 sem a necessidade de carregá-los para o Redshift.
- É necessário ter um cluster do Redshift disponível para iniciar a consulta.
- A consulta é distribuída para milhares de nós do Redshift Spectrum, garantindo alta performance.

----------------------------------------------------------

***Aurora***
criada em 2014
proprietária da amazon, compatível com (mysql) e PostgreSQL
5x mais rapido que o mysql e 3x melhor que os bancos de dados PostgreSQL
oferece um preço muito mais baixo, ao mesmo tempo em que oferece desempenho e disponibilidade semelhantes
10G -> autoscaling automático 
temos a database principal que podemos fazer réplicas, na principal fazemos escrita e nas réplicas fazemos leitura
podemos cria 15 réplicas de leitura
latência baixa
recover -> point in-time -> podemos recuperar a database de dias atras
backup continuo -> 3 zonas e disponível no s3

* comece com 10 GB. escalonável em incrementos de 10 GB até 128 TB (auto scaling de armazenamento)
* os recursos de computação podem ser dimensionados para até 96 vCPUS e 768 GB de memória
* 2 Cópias dos seus dados estão contidas em cada Zona de disponibilidade, com um mínimo de 3 zonas de disponibilidade. 6 cópias dos seus dados

Scaling aurora

* o Aurora foi projetado para lidar de forma transparente com a perda de até duas cópias de dados sem afetar a disponibilidade de gravação do banco
  de dados e de até três cópias sem afetar a disponibilidade de leitura
* O armazenamento aurora também é auto-recuperável. blocos de dados e discos são continuamente verificados em busca de erros e reparados automaticamente

3 tipos de replicas com aurora
* atualmente você pode ter 15 réplicas de leitura com o Aurora, tanto aurora mysql e PostgreSQL oferecem suporte a 15 réplicas

Backups com aurora

* os backups automatizados estão sempre habilitados nas instâncias de banco de dados do amazona aurora. Os backups não afetam o desempenho do banco de dados
* você também pode tirar snapshots com aurora. isso também não afeta o desempenho
* você pode compartilhar snapshots do aurora com outras contas da aws

Aurora serverless
* uma configuração de escalonamento automático sob demanda para as edições do amazona aurora compatíveis com mysql e PostgreSQL. um cluster de banco de 
  dados aurora serverless inicia, desliga e aumenta ou diminui automaticamente a capacidade com base nas necessidades do seu aplicativo

Casos de uso com aurora serverless
o aurora serverless oferece um opção relativamente simples e econômica para cargas de trabalho pouco frequentes, intermitentes ou imprevisíveis.

==================================================================================

Route 53

política de roteamento

Simple routing policy (Política de roteamento simples): use para um único recurso que executa uma determinada função para seu domínio, por exemplo, um servidor Web que oferece conteúdo para o site example.com. Você pode usar roteamento simples para criar registros em uma zona hospedada privada. Se você 
escolher a política de roteamento simples, poderá ter apenas um registro com vários endereços IP. Se você especificar vários valores em um registro, o Route
53 retornará todos os valores ao usuário em ordem alatória.

Failover routing policy (Política de roteamento de failover): use quando quiser configurar o failover ativo-passivo (ativo -> site primário e passivo -> site secundário). Você pode usar roteamento com failover para criar registros em uma zona hospedada privada. Exemplo, você pode querer que seu site primário esteja em EU-WEST-2 e seu site secundário de DR/recuperação de desastres em AP-SOUTHEAST-2. o Route 53 monitorará a integridade do seu site primário usando uma verificação de integridade.

Geolocation Routing Policy (Política de Roteamento de Geolocalização): Use essa política quando quiser encaminhar o tráfego com base na localização dos usuários. A política de roteamento de geolocalização permite que você escolha para onde o tráfego será enviado com base na localização geográfica dos seus usuários (ou seja, o local de origem das consultas DNS). Vale lembrar que essa política só pode ser usada em zonas hospedadas públicas.

* Casos de Uso: Por exemplo, você pode querer que todas as consultas da Europa sejam roteadas para uma frota de instâncias do EC2 configuradas especificamente para seus clientes europeus. Esses servidores podem ter o idioma local dos seus clientes europeus e exibir todos os preços em euros.

Geoproximity Routing Policy (Política de Roteamento por Geoproximidade): O roteamento por geoproximidade permite que o Route 53 direcione o tráfego para seus recursos com base na localização geográfica dos seus usuários e recursos. Opcionalmente, você também pode optar por rotear mais ou menos tráfego para um determinado recurso, ajustando um valor conhecido como "tendência". Para usar o roteamento por geoproximidade, você deve utilizar o Route 53 Traffic Flow.

Política de roteamento por latência: use quando tiver recursos em várias Regiões da AWS e quiser rotear o tráfego para a região que ofereça a melhor latência. Você pode usar roteamento por latência para criar registros em uma zona hospedada privada.
  Conjunto de registro de recursos de latência: Para usar o roteamento baseado em latência, você cria um conjunto de registros de recursos de latência para      o recurso EC2 (ou ELB) em cada região que hospeda seu site. Quando o route 53 recebe uma consulta para seu site, ele seleciona o conjunto de registros de recursos de latência para a região que fornece ao usuário a latência mais baixa.

IP-based routing policy (Política de roteamento baseado em IP): use quando quiser rotear o tráfego com base no local dos usuários e tiver os endereços IP de origem do tráfego.

Multivalue answer routing policy (Política de roteamento de resposta com vários valores): use quando quiser que o Route 53 responda a consultas de DNS com até oito registros íntegros selecionados aleatoriamente. Você pode usar roteamento com resposta multivalor para criar registros em uma zona hospedada privada. Parece muito o roteamento simples, só que no multivalue tem health check integrado.

Weighted routing policy (Política de roteamento ponderado): use para encaminhar o tráfego para vários recursos nas proporções que você especificar. Você pode usar roteamento ponderado para criar registros em uma zona hospedada privada. Permite que você divida seu tráfego com base em diferentes pesos atribuídos. Por exemplo, você pode definir 10% do seu tráfego para us-east-1 e 90% para eu-west-1
  Health checks
    * você pode definir verificações de integridade em conjuntos de registros individuais.
    * se um conjunto de registros falhar na verificação de integridade, ele será removido da rota 53 até passar na verificação de integridade
    * você pode definir notificações do SNS para alertá-lo sobre falhas nas verificações de integridade.


==================================================================================
CloudFront

O Amazon CloudFront é um serviço de rede de entrega de conteúdo (CDN) criado para alta performance, segurança e conveniência do desenvolvedor.

Rede de Distribuição de Conteúdo (CDN)
Melhora o desempenho de leitura ao armazenar conteúdo em cache nas localizações de borda (edge locations).
Melhora a experiência do usuário com menor latência e tempo de carregamento mais rápido.
216 Pontos de Presença globalmente (localizações de borda) para atender aos usuários em diferentes regiões do mundo.
Proteção contra DDoS, com integração com AWS Shield e AWS Web Application Firewall (WAF) para maior segurança.

CloudFront – Origens
S3 bucket

Para distribuir arquivos e armazená-los em cache nas localizações de borda.
Segurança aprimorada com CloudFront Origin Access Control (OAC), que substitui o Origin Access Identity (OAI).
CloudFront pode ser usado como ingresso (para enviar arquivos para o S3).

Custom Origin (HTTP)

Application Load Balancer
Instância EC2
S3 website (é necessário primeiro habilitar o bucket como um site estático do S3).
Qualquer backend HTTP que você desejar.

----------------------------------------------------------

CloudFront vs S3 Cross Region Replication

CloudFront:
Rede de borda global (Pontos de presença espalhados pelo mundo).
Arquivos são armazenados em cache por um tempo determinado (TTL), geralmente um dia.
Ideal para conteúdo estático que precisa estar disponível em qualquer lugar do mundo.
Melhora a experiência do usuário com acesso rápido a conteúdo frequentemente acessado.

S3 Cross Region Replication:
Requer configuração para cada região onde você deseja que a replicação aconteça.
Arquivos são atualizados em tempo quase real entre as regiões.
Somente leitura nas regiões de destino.
Ideal para conteúdo dinâmico que precisa ser acessado em poucas regiões com baixa latência.

----------------------------------------------------------

CloudFront Geo Restriction
Restrição de acesso: Você pode limitar quem pode acessar sua distribuição com base na localização geográfica do usuário.

Allowlist:
Permite o acesso ao conteúdo somente para usuários localizados em países da lista de países aprovados.

Blocklist:
Impede o acesso ao conteúdo para usuários localizados em países da lista de países proibidos.

A localização do país é determinada utilizando um banco de dados Geo-IP de terceiros.

Caso de uso:
Leis de direitos autorais para controlar o acesso ao conteúdo com base na localização geográfica dos usuários.

----------------------------------------------------------
CloudFront – Invalidações de Cache

Quando você atualiza o origin back-end, o CloudFront não sabe sobre a mudança e só buscará o conteúdo atualizado após o tempo de vida (TTL) expirar.
No entanto, você pode forçar uma atualização completa ou parcial do cache (ignorando o TTL) realizando uma Invalidação do CloudFront.

Você pode invalidar:
Todos os arquivos (*), ou
Um caminho específico, como /images/*.

==================================================================================
>>>EBS<<<
a ec2 e o voluem ebs tem de estar na mesma az/zona de disponibilidade
ebs mult-attach -> duas instância ou mais para conectar no mesmo disco ebs e tem de ser do tipo io 1 e as ec2 tem de ser do tipo nitro

tipos de volumes EBS:
ssd -> mais rápido mais caro
hdd -> mais lento e mais barato

Amazon EBS) que possa suportar até 20.000 IOPS ?
	SSD de IOPS provisionado, um volume de SSD de IOPS provisionado do EBS fornece até 64.000 IOPS para cada volume.

Os volumes EBS tem 6 tipos
  * gp2/gp3 (ssd): volume SSD de uso geral que equilibra preço e desempenho para uma ampla variedade de cargas de trabalho
  * io1/io2 block express(ssd): volume ssd de mais alto desempenho para cargas de trabalho de baixa latência ou alto rendimento de missão crítica
  * st1(hdd): volume de hdd de baixo custo projetado para cargas de trabalho de acesso frequente e com alto rendimento
  * sc1(hdd): volume de hdd de menor custo projetado para cargas de trabalho acessadas como menos frequência

Os volumes EBS são caracterizados em tamanho | rendimento | iops (operação de E/S por segundo)
Somente gp2/gp3 e io1/io2 block express podem ser usados  como volumes de inicialização 

Casos de uso de tipos de volumes EBS SSD de uso geral
  * armazenamento econômico e baixa latência
  * volumes de inicialização de sistema, desktops virtuais, ambientes de desenvolvimento e teste
  * 1 GiB a 16 Gib
GP3:
  * Geração mais recente de volumes
  * linha de base de 3000 IOPS e taxa de transferência de 125 MiB/s
  * Pode aumentar o IOPS em até 16000 e a taxa de transferência em até 1000 MiBs/s de forma independente
  * ideal para aplicações que exigem alto desempenho com baixo custo, com Mysql, Cassandra, desktops virtuais e análises hadoop
GP2:
  * Geração mais antiga
  * pequenos volumes gp2 podem aumentar o IOPS para 3000
  * o tamanho do volume e o IOPS estão vinculados, o IOPS máximo é 16000
  * 3 IOPS por GB, significa que com 5334 GB estamos no IOPS máximo

Casos de uso de tipos de volumes EBS SSD de IOPS provisionadas (PIOPS)
  carga de trabalho de banco de dados que é muito sensível ao desempenho e a consistencia do armazenamento, os volumes provisionados serão ótimos
  * aplicativos de negócios críticos com desempenho de IOPS sustentado
  * Ou aplicativos que precisam de mais de 16000 IOPS
  * ótimo para cargas de trabalho de banco de dados (sensível ao desempenho e a consistência do armazenamento)
  * io1 (4GiB - 16TiB):
    * Máximo de PIOPS:64000 para instancias nitro ec2 e 32000 para outras
    * pode aumentar PIOPS independentemente do tamanho do armazenamento
  * io2 block express (4Gib - 64TiB):
    * latencia inferior a milissegundos
    * máximo de PIOPS: 256000 com uma proporção IOPS:GiB de 1000:1
    * io2 é o mesmo preço que o io1
    * durabilidade de 99.999% em vez de 99.9%
  * Suporta EBS Multi-attach

TIPOS DE VOLUMES EBS CASOS DE USO 
UNIDADES DE DISCO RÍGIDO (HDD)
  * não pode ser um volume de inicialização
    * 125 GiB a 16 TiB
  * HDD otimizado para rendimento (st1)
    * big data, data warehouse, processamento de logs
    * taxa de transferencia máxima de 500 MiB/s - IOPS máximo de 500
  * HDD frio (scl):
    * para dados que são acessados com pouca frequência
    * cenários onde o menor custo é importante
    * taxa de transferencia máxima de 250 MiB/s - IOPS máximo de 250 


EBS Multi-Attach - família io1/io2 
  * Anexe o mesmo volume EBS a várias instâncias do EC2 na mesma AZ
  * Cada instância tem permissões totais de leitura e gravação no volume de alto desempenho
  * CASOS DE USO
    * Obtenha maior disponibilidade de aplicativos em aplicativos Linux em Cluster (ex.: TERADATA)
    * Os aplicativos devem gerenciar operações de gravação simultâneas
    * Até 16 instancias EC2 por vez
  * Deve usar um sistema de arquivos com reconhecimento de cluster (não XFS, EXT4, etc...)

CRIPTOGRAFIA EBS
  * Ao criar um volume EBS criptografado, você obtém o seguinte:
    * Os dados em repouso são criptografados dentro do volume
    * Todos os dados em movimento entre as instância e o volume são criptografados
    * Todos os snaphots são criptografados
    * Todos os volumes criados a partir do snapshot
  * A criptografia e a descriptografia são tratadas de forma transparente (você não tem nada para fazer)
  * A criptografia tem um impacto mínimo na latência
  * A criptografia EBS aproveita chaves do KMS (AES-256)
  * Copiar um snapshot não criptografado permite a criptografia
  * Snapshot de volumes criptografados são criptografados

Criptografia: criptografe um volume EBS não criptografado
  * Crie um snapshot EBS do volume raiz não criptografado
  * crie uma cópia do snapshot e selecione a opção de criptografia
  * Crie um novo volume ebs a partir do snapshot (o volume também será criptografado)
  * Agora você pode anexar o volume criptografao a instância original

IOPS
* mede o número de operações  de leitura e gravação por segundo
* métrica importante para transações rápidas, aplicativos de baixa latência e cargas de trabalho transacionais
* a capacidade de ação lê e escrever muito rapidamente
* escolha SSD de IOPS provisionados (io1 ou io2)

Throughput
* mede o número de bits lidos ou escritos por segundo (MB/s)
* métrica importante para grandes conjuntos de dados, grandes tamanhos de E/S e consultas complexas
* a capacidade de lidar com grandes conjuntos de dados
* escolha HDD otimizado para taxa de transferência (st1)

---------------------------------------------------------------
>>>ARMAZENAMENTO EM INSTÂNCIA/INSTANCE STORE<<<

Definição: EC2 (Elastic Compute Cloud) é o serviço de computação em nuvem da AWS, e o armazenamento em instância é uma opção de armazenamento temporário diretamente associada à instância EC2.

Características: O armazenamento em instância é localizado no host físico da instância EC2, proporcionando alta taxa de transferência e baixa latência, ideal para aplicativos que requerem acesso rápido a dados temporários.

Efemeridade: O armazenamento em instância é efêmero, o que significa que os dados armazenados são perdidos quando a instância é parada ou terminada. Portanto, não é adequado para armazenar dados persistentes.

Desempenho: Oferece alto desempenho para cargas de trabalho que exigem acesso rápido a dados, como caches, bancos de dados temporários e processamento de dados temporários.

Tipos de Instâncias: Nem todos os tipos de instâncias EC2 suportam armazenamento em instância. É importante selecionar instâncias que ofereçam esse recurso, como as instâncias do tipo "I3" ou "C5d".

Backup e Persistência: Devido à efemeridade do armazenamento em instância, é essencial implementar estratégias de backup e persistência de dados usando outros serviços da AWS, como o Amazon S3 ou o Amazon EBS.

Segurança: Como os dados armazenados em instâncias são temporários, é importante garantir que informações sensíveis sejam adequadamente criptografadas e protegidas, seguindo as práticas recomendadas de segurança da AWS.

Custo: O armazenamento em instância é parte do custo total da instância EC2 e geralmente é incluído no preço da instância. No entanto, os custos podem variar com base no tipo e tamanho da instância.

Uso Adequado: É crucial compreender os casos de uso ideais para o armazenamento em instância e aplicá-lo em cenários onde sua alta performance e efemeridade são vantajosas.

Monitoramento e Manutenção: Monitorar a integridade e o desempenho do armazenamento em instância é essencial para garantir o bom funcionamento das aplicações. A manutenção regular das instâncias também é necessária para garantir o desempenho ideal.

==================================================================================
EFS -> elastic file system
O Amazon Elastic File System (EFS) aumenta e diminui automaticamente conforme você adiciona e remove arquivos, sem a necessidade de gerenciamento ou provisionamento.

as instâncias podem estar em vpc diferente que ainda conseguem acessar o EFS
as instâncias podem estar em az diferente que ainda conseguem acessar o EFS
as instâncias podem estar em regiões diferentes que ainda conseguem acessar o EFS

* NFS (network file system) gerenciado que pode ser montado em muitos EC2
* EFS funciona com instâncias EC2 em multi-AZ
* Altamente disponível, escalável, caro (3x gp2), pagamento por uso

CASOS DE USO: gerenciamento de conteúdo, serviço web, compartilhamento de dados, wordpress
* usa protocolo NFSv4.1 
* usa grupo de segurança para controlar o acesso ao EFS
* Compatível com AMI baseada em Linux (não windows)
* criptografia em repouso usando KMS

* Sistema de arquivos POSIX(~Linux) que possui uma API de arquivo padrão
* O sistema de arquivos é dimensionado automaticamente, pago conforme o uso, sem planejamento de capacidade!


PERFORMANCE & STORAGE CLASSES
* EFS SCALE
  * milhares de clientes NFS simultâneos, taxa de transferência de 10GB+/s
  * Crescer automaticamente para o sistema de arquivos de rede em escala de petabytes

* MODO DE DESEMPENHO (definido no momento da criação de EFS)
  * finalidade geral (padrão) - casos de uso sensíveis a latência (servidor web, CMS, etc...)
  * Max I/O - maior latência, rendimento, altamente paralelo (big data, processamento de mídia)

* Modo de rendimento/throughput mode
  * Burst: 1TB=50MiB/s + burst de até 100MiB/s
  * Provisionado: defina sua taxa de transferência independentemente do tamanho do armazenamento, por exemplo: 1GB/s para armazenamento de 1TB
  * Elastic: aumenta ou diminui automaticamente a taxa de transferência com base em suas cargas de trabalho
    * Até 3GiB/s para leituras e 1GiB/s para escrita
    * usado para cargas de trabalho imprevisíveis

CLASSES DE ARMAZENAMENTO
Camadas de armazenamento(recurso de gerenciamento de ciclo de vida - Mover arquivo após N dias)
* standard: para arquivos acessados com frequência
* Infrequent access (EFS-IA):Custo para recuperar arquivos, menor preço para armazenar
* Archive: dados raramente acessados (poucas vezes por ano), 50% mais barato
* Implemente políticas de ciclo de vida para mover arquivos entre camadas de armazenamento

DISPONIBILIDADE DE DURABILIDADE
* Standard: Multi-AZ, ótimo para produção
* One Zone: One AZ, ótimo para desenvolvedores, backup habilitado por padrão, compatível com IA (EFS ONE ZONE-IA)
* Mais de 90% em economia de custos

>>>EBS vs EFS<<<
VOLUME EBS
* uma instancia (exceto multi-attach io1/io2)
* estão bloqueados no nível da zona de disponibilidade (AZ).
* gp2:10 aumenta se o tamanho do disco aumentar
* gp3 e io1: podem aumentar io de forma independente
Para migrar um volume EBS entre AZ
* tire um snapshot 
* restaurar o snapshot para outra AZ
* os backups do EBS usam IO e você não deve executá-los enquanto seu aplicativo estiver lidando com muito tráfego
Os volumes raiz EBS das instâncias serão encerrados por padrão se a instância ec2 for encerrada. (você pode desativar isso)
------------
EFS
* montagem de centenas de instâncias em AZ
* EFS compartilha arquivos de sites(wordpress)
* Somente para instâncias Linux(POSIX)
* EFS tem um preço mais alto que EBS
* pode aproveitar os níveis de armazenamento para economizar custos
* Lembre-se: EFS x EBS x Armazenamento de instâncias
==================================================================================
Amazon Kinesis -> é um serviço serveless, que analisa dados em tempo real (decisões mais rapidas)

Kinesis data stream recebe os dados, armazena e indexa para a próxima etapa, 24h -> 7 dias, armazena em shad
kineses data firehose -> carrega esses dados para um destino específico, ex.: s3   | 0 horas
Kinesis data analytics -> recebe os dados do stream, pode usar um função lambda para fazer a leitura

Kinesis Data Analytics (Aplicação SQL)

  Análise em tempo real em Kinesis Data Streams e Firehose usando SQL.
  Adicione dados de referência do Amazon S3 para enriquecer os dados de streaming.
  Totalmente gerenciado, sem necessidade de provisionar servidores.
  Escalabilidade automática.
  Pagamento pelo consumo real.
Saídas:
  Kinesis Data Streams: Crie streams a partir das consultas de análise em tempo real.
  Kinesis Data Firehose: Envie os resultados das consultas de análise para destinos.
Casos de uso:
  Análise de séries temporais.
  Painéis em tempo real.
  Métricas em tempo real.

Kinesis Data Analytics for Apache Flink 
Use Flink (Java, Scala ou SQL) para processar e analisar dados de streaming.
Execute qualquer aplicação Apache Flink em um cluster gerenciado na AWS.
Provisionamento de recursos de computação, computação paralela, escalabilidade automática.
Backups de aplicação (implementados como checkpoints e snapshots).
Utilize qualquer recurso de programação do Apache Flink.
Flink não lê diretamente do Firehose (use o Kinesis Analytics para SQL em vez disso).



==================================================================================
SQS -> simpe queue service
	standart - envia requisições não é em ordem
	fifo - primeiro a entrar primeiro a sair
é pull base, as informações tem de ser requeridas a ele

Desacople sistemas e aumente a escalabilidade - SNS e SQS.
==================================================================================
SNS -> SIMPLE NOTIFICATION SERVICE
sistema de notificação, na parte de alerta dos preços na aws
push notification -> mobile
sms
text message
email
http
paga pelo o que você usa

quando cria um alerta você cria um tópico

Desacople sistemas e aumente a escalabilidade - SNS e SQS.
==================================================================================
SWF -> simple workflow service
conjunto de tarefas de devem ser executadas numa ordem específica
automatizar ou uma interface que pensa quase como um ser humano
automatiza e integra toda sua aplicação dentro de um processo
pode ser 10.000 tarefas, 1000 tarefas por segundo

==================================================================================
ELASTIC TRANSCODER
converte mídias para diversos dispositivos

==================================================================================
API GATEWAY

==================================================================================
Cognito -> Com o Amazon Cognito, você pode adicionar recursos de inscrição e login de usuários e controlar o acesso a suas aplicações móveis e da Web.
fazer login com o google ou facebook, github
consegue filtrar permissões em sites, o que pode ou não acessar num site de curso

==================================================================================

Disaster Recovery Overview

- Qualquer evento que tenha um impacto negativo na continuidade dos negócios ou nas finanças de uma empresa é um desastre.
- Recuperação de desastres (Disaster Recovery - DR) é sobre se preparar e se recuperar de um desastre.
- Que tipo de recuperação de desastres?
- On-premise => On-premise: DR tradicional, e muito caro.
- On-premise => Nuvem AWS: recuperação híbrida.
- Região AWS Cloud A => Região AWS Cloud B.
- É necessário definir dois termos:
- RPO: Objetivo de Ponto de Recuperação (Recovery Point Objective).
- RTO: Objetivo de Tempo de Recuperação (Recovery Time Objective).


------------------------------------------------------

Opções de recuperação de desastres na nuvem

Backup & Restore
	RPO/RTO: horas
	* casos de uso de prioridade mais baixa
	* provisionar todos os recursos da aws após o evento
	* restaurar backups após evento
	* custo baixo $

------------------------------------------------------

Pilot Light
	RPO/RTO:10S de minutos
	* dados ao vivo
	* serviços ociosos
	* provisionar alguns recursos da aws e dimensionar após o evento
	* custo: $$

Uma versão reduzida da aplicação está sempre em execução na nuvem.
Útil para o núcleo crítico (pilot light).
Muito semelhante ao método de Backup e Restauração.
Mais rápido do que Backup e Restauração, pois os sistemas críticos já estão ativos.

------------------------------------------------------

Warm standby
	RPO/RTO: Minutes
	* sempre funcionando, mas menor
	* critico para os negócios
	* dimensione os recursos da aws após o evento
	* custo $$$
Essa solução atende ao requisito de um RTO de cinco minutos com uma instância em execução mínima. As instâncias são executadas com baixa capacidade e podem ser dimensionadas em minutos.

O sistema completo está ativo e em funcionamento, mas com tamanho mínimo.
Em caso de desastre, é possível escalar para a carga de produção.

------------------------------------------------------

Multi-site active/active
	RPO/RTO: tempo real
	* tempo de inatividade zero
	* perda de dados quase nula
	* serviços de missão crítica
	* custo $$$$

RTO muito baixo (em minutos ou segundos) – extremamente caro.
Escala completa de produção está em execução tanto na AWS quanto no ambiente On-Premise.

------------------------------------------------------

Dicas para Recuperação de Desastres

Backup:

Snapshots do EBS, backups automáticos / Snapshots do RDS, etc.
Envio regular de dados para S3 / S3 IA / Glacier, com Políticas de Ciclo de Vida e Replicação entre Regiões.
Para ambientes On-Premise: uso do Snowball ou Storage Gateway.

Alta Disponibilidade:

Use o Route53 para migrar DNS de uma Região para outra.
Utilize RDS Multi-AZ, ElastiCache Multi-AZ, EFS e S3.
Configure VPN Site-to-Site como recuperação para o Direct Connect.

Replicação:

Replicação do RDS (entre Regiões), AWS Aurora com Bancos de Dados Globais.
Replicação de banco de dados de ambientes On-Premise para RDS.
Uso do Storage Gateway.

Automação:

Utilize CloudFormation ou Elastic Beanstalk para recriar um ambiente totalmente novo.
Recupere ou reinicie instâncias EC2 com o CloudWatch, caso alarmes falhem.
Configure funções AWS Lambda para automações personalizadas.

Caos:

A Netflix utiliza uma "simian-army" para encerrar aleatoriamente instâncias EC2, testando a resiliência do sistema.

==================================================================================

AWS Global Accelerator 

O AWS Global Accelerator usa a vasta rede global da AWS sem congestionamento para rotear o tráfego TCP e UDP para um endpoint de aplicativo íntegro na região da AWS mais próxima do usuário.

Isso significa que ele direcionará o tráfego de forma inteligente para o ponto de presença mais próximo (reduzindo a latência). O failover contínuo é garantido, pois o AWS Global Accelerator usa o endereço IP anycast, o que significa que o IP não muda ao fazer failover entre regiões, para que não haja problemas com caches de clientes com entradas incorretas que precisam expirar.

Esta é a única solução que fornece failover determinístico.

Global Users for Our Application

Você implantou um aplicativo com usuários globais que desejam acessá-lo diretamente.
Eles acessam o aplicativo pela internet pública, o que pode adicionar muita latência devido a múltiplos hops.
O objetivo é minimizar a latência ao passar pela rede AWS, aproveitando a infraestrutura otimizada da AWS.

Solução:
Global Accelerator: Use o AWS Global Accelerator para direcionar o tráfego de forma inteligente para os pontos de presença (edge locations) mais próximos dos usuários.
ALB (Application Load Balancer): O tráfego pode ser direcionado por um ALB público, mas isso pode resultar em latência devido aos hops adicionais.
Com o Global Accelerator, você pode otimizar o caminho de rede, aproveitando a rede global da AWS para reduzir a latência e melhorar a experiência do usuário em regiões como América, Austrália, Europa e Índia.

----------------------

Unicast IP vs Anycast IP

Unicast IP:

Um servidor possui um endereço IP.
O tráfego é enviado para um único destino (o servidor que possui aquele IP).

Anycast IP:

Vários servidores compartilham o mesmo endereço IP.
O cliente é roteado para o servidor mais próximo (geralmente, aquele com a menor latência) usando a rede.

Exemplo de uso do Anycast:
Utilizado em redes de Content Delivery Network (CDN) ou DNS, onde a localização do servidor mais próxima é escolhida automaticamente para melhorar a performance e reduzir a latência.

------------------------

AWS Global Accelerator

O AWS Global Accelerator é um serviço que melhora a performance e disponibilidade de aplicativos para usuários globais. Ele aproveita a rede interna da AWS para rotear o tráfego até seu aplicativo, proporcionando uma redução de latência e uma experiência mais rápida para os usuários.

Como funciona:
Criação de 2 IPs Anycast:
O Global Accelerator cria dois endereços IP Anycast para seu aplicativo, que são usados para direcionar o tráfego de forma eficiente.

Roteamento para as Localizações de Edge:
O tráfego é enviado para as Edge Locations da AWS (pontos de presença ao redor do mundo), que são servidores distribuídos globalmente.

Roteamento para o Aplicativo:
A partir das Edge Locations, o tráfego é encaminhado de forma otimizada para o destino final do aplicativo, reduzindo a latência ao evitar múltiplos hops e utilizando a rede interna da AWS.

Benefícios:
Redução da latência: Aproveita a rede interna da AWS, evitando rotas ineficientes pela internet pública.
Alta disponibilidade: Garante o acesso ao aplicativo mesmo que um endpoint falhe, redirecionando automaticamente o tráfego para o próximo ponto de presença.
Melhora da performance: Tráfego é direcionado para o local mais próximo do usuário, otimizando a entrega de conteúdo.
Esse serviço é ideal para aplicações globais que precisam de alta performance e baixa latência, como jogos online, aplicativos de mídia, e-commerce e outras plataformas de grande escala.

----------------------------

Funciona com Elastic IP, instâncias EC2, ALB, NLB, público ou privado
Desempenho consistente
Roteamento inteligente para a menor latência e rápido failover regional
Sem problemas com o cache do cliente (porque o IP não muda)
Rede interna da AWS
Verificações de saúde
O Global Accelerator realiza uma verificação de saúde de suas aplicações.
Ajuda a tornar sua aplicação global (failover em menos de 1 minuto para instâncias não saudáveis).
Ótimo para recuperação de desastres (graças às verificações de saúde).
Segurança
Apenas 2 IPs externos precisam ser liberados na lista de permissões (whitelisted).
Proteção contra DDoS graças ao AWS Shield.

-----------------------------

AWS Global Accelerator vs CloudFront

Ambos utilizam a rede global da AWS e suas localizações de borda (edge locations) ao redor do mundo.
Ambos os serviços integram-se com o AWS Shield para proteção contra DDoS.

CloudFront
Melhora o desempenho para conteúdo cacheável (como imagens e vídeos).
Melhora o desempenho para conteúdo dinâmico (como aceleração de APIs e entrega de sites dinâmicos).
O conteúdo é servido na borda.

Global Accelerator
Melhora o desempenho para uma ampla gama de aplicativos usando TCP ou UDP.
Proxy de pacotes na borda para aplicativos em execução em uma ou mais regiões da AWS.
Ótimo para casos de uso não-HTTP, como jogos (UDP), IoT (MQTT) ou Voz sobre IP (VoIP).
Bom para casos de uso HTTP que exigem endereços IP estáticos.
Bom para casos de uso HTTP que exigem failover regional rápido e determinístico.

==================================================================================

ElastiCache
O Amazon ElastiCache é um serviço de cache na memória totalmente gerenciado que oferece suporte a casos de uso flexíveis e em tempo real. Você pode usar o ElastiCache para armazenamento em cache, que acelera o desempenho de aplicativos e bancos de dados, ou como um armazenamento de dados primário para casos de uso que não exigem durabilidade, como armazenamentos de sessão, placares de jogos, streaming e análises. O ElastiCache é compatível com Redis e Memcached.

Como os problemas nesta instância são causados ​​por baixo desempenho de leitura, uma solução de armazenamento em cache descarregaria as leituras da instância de banco de dados primária e permitiria que o aplicativo tivesse um desempenho melhor.

==================================================================================
AWS Glue
O AWS Glue é um serviço gerenciado de transformação de dados.

Serviço gerenciado de extração, transformação e carregamento (ETL).
Útil para preparar e transformar dados para análises.
Serviço totalmente sem servidor (serverless).

Glue – Pontos importantes para saber de forma geral 

 - Glue Job Bookmarks: Impede o reprocessamento de dados antigos.
 - Glue Elastic Views:
   - Combina e replica dados através de múltiplos data stores usando SQL.
   - Sem código personalizado, o Glue monitora mudanças nos dados de origem, serverless.
   - Utiliza uma "tabela virtual" (view materializada).
Glue DataBrew: Limpeza e normalização de dados usando transformações pré-construídas.
Glue Studio: Nova interface gráfica (GUI) para criar, executar e monitorar jobs ETL no Glue.
Glue Streaming ETL (construído em Apache Spark Structured Streaming):
  - Compatível com Kinesis Data Streaming, Kafka, MSK (Kafka gerenciado).

==================================================================================

Data Migrations com AWS Snow Family

Desafios:
• Conectividade limitada
• Largura de banda limitada
• Alto custo de rede
• Largura de banda compartilhada (não é possível maximizar a linha)
• Estabilidade da conexão

AWS Snow Family: dispositivos offline para realizar migrações de dados
Se a transferência pela rede levar mais de uma semana, use os dispositivos Snowball!

Processo de Uso do Snow Family

Solicite dispositivos Snowball pelo console da AWS para entrega.
Instale o cliente Snowball / AWS OpsHub nos seus servidores.
Conecte o Snowball aos seus servidores e copie os arquivos usando o cliente.
Envie o dispositivo de volta quando terminar (ele será enviado para a instalação correta da AWS).
Os dados serão carregados em um bucket S3.
O Snowball será completamente apagado.

------------

O que é Edge Computing?

Processa dados enquanto eles são criados em uma localização remota (edge).
Um caminhão na estrada, um navio no mar, uma estação de mineração subterrânea...
Esses locais podem ter internet limitada e nenhuma infraestrutura computacional disponível.
Configuramos um dispositivo Snowball Edge ou Snowcone para realizar edge computing.
Snowcone: 2 CPUs, 4 GB de memória, acesso com ou sem fio.
Snowball Edge: otimizado para computação (Compute Optimized) ou armazenamento (Storage Optimized).
Permite rodar instâncias EC2 ou funções Lambda na borda.
Casos de uso: pré-processamento de dados, aprendizado de máquina, transcodificação de mídia.

------------

Arquitetura da Solução: Snowball para Glacier

O Snowball não pode importar dados diretamente para o Glacier.
É necessário primeiro enviar os dados para o Amazon S3.
Em seguida, utilizar uma política de ciclo de vida do S3 para mover os dados para o Glacier automaticamente.

------------

Amazon FSx – Visão Geral

Implanta sistemas de arquivos de alto desempenho de terceiros na AWS.
Serviço totalmente gerenciado.

Amazon FSx for Windows (File Server)

FSx for Windows é um sistema de arquivos Windows totalmente gerenciado.
Suporta o protocolo SMB e o sistema de arquivos Windows NTFS.
Integra-se ao Microsoft Active Directory, com suporte a ACLs e quotas de usuários.
Pode ser montado em instâncias EC2 Linux.
Suporta o Microsoft Distributed File System (DFS) Namespaces para agrupar arquivos em múltiplos FS.
Escalabilidade: até dezenas de GB/s, milhões de IOPS e centenas de PB de dados.
Opções de Armazenamento:
SSD: Para workloads sensíveis à latência (bancos de dados, processamento de mídia, análise de dados, etc.).
HDD: Para uma ampla gama de workloads (diretórios pessoais, CMS, etc.).
Outros Recursos:
Pode ser acessado a partir da sua infraestrutura on-premises via VPN ou Direct Connect.
Suporte a configuração Multi-AZ para alta disponibilidade.
Os dados são backupados diariamente no Amazon S3.

------------

Amazon FSx for Lustre

Lustre é um sistema de arquivos distribuído paralelo, projetado para computação em larga escala.
O nome Lustre vem da junção de "Linux" e "Cluster".
Usado em Machine Learning, High Performance Computing (HPC), processamento de vídeo, modelagem financeira e automação de design eletrônico.
Escalabilidade: até centenas de GB/s, milhões de IOPS e latências abaixo de 1 ms.
Opções de Armazenamento:
SSD: Para workloads de baixa latência, alta demanda de IOPS, arquivos pequenos e operações aleatórias.
HDD: Para workloads com alto throughput, arquivos grandes e operações sequenciais.
Integração com S3:
Permite ler diretamente do S3 como um sistema de arquivos através do FSx.
Pode escrever os resultados dos cálculos de volta para o S3 através do FSx.
Outros Recursos:
Pode ser acessado a partir de servidores on-premises via VPN ou Direct Connect.

FSx for Lustre - Opções de Implantação do Sistema de Arquivos

1. Scratch File System
 Armazenamento temporário.
 Os dados não são replicados (se o servidor falhar, os dados são perdidos).
 Alto desempenho com picos de velocidade (até 6x mais rápido, 200 MBps por TiB).
 Uso recomendado:
  Processamento de curto prazo.
  Otimização de custos.

2. Persistent File System
 Armazenamento de longo prazo.
 Os dados são replicados dentro da mesma AZ.
 Arquivos perdidos podem ser recuperados em minutos.
 Uso recomendado:
  Processamento de longo prazo.
  Dados sensíveis que exigem alta disponibilidade.

------------

Amazon FSx for NetApp ONTAP

Serviço gerenciado do NetApp ONTAP na AWS.
Sistema de arquivos compatível com os protocolos NFS, SMB e iSCSI.
Permite migrar workloads que já rodam em ONTAP ou NAS para a AWS.

Compatível com:
Linux, Windows e macOS
VMware Cloud on AWS
Amazon Workspaces & AppStream 2.0
Amazon EC2, ECS e EKS

Recursos:
Armazenamento elástico: cresce ou diminui automaticamente.
Snapshots e replicação para proteção de dados.
Baixo custo, compressão e desduplicação de dados.
Clone instantâneo em um ponto no tempo, útil para testes de novos workloads.

------------

Amazon FSx for OpenZFS

Serviço gerenciado do OpenZFS na AWS.
Sistema de arquivos compatível com NFS (v3, v4, v4.1, v4.2).
Permite migrar workloads que já utilizam ZFS para a AWS.

Compatível com:
Linux, Windows e macOS
VMware Cloud on AWS
Amazon Workspaces & AppStream 2.0
Amazon EC2, ECS e EKS

Recursos:
Até 1.000.000 IOPS com latência abaixo de 0.5 ms.
Snapshots, compressão e armazenamento de baixo custo.
Clone instantâneo em um ponto no tempo, útil para testes de novos workloads

------------

AWS Storage Gateway
Ponte entre dados on-premises e dados na nuvem.

Casos de uso:
Recuperação de desastres.
Backup e restauração.
Armazenamento em camadas.
Cache on-premises e acesso a arquivos de baixa latência.

Tipos de Storage Gateway:
S3 File Gateway
FSx File Gateway
Volume Gateway
Tape Gateway

Aws Storage Gateway -> permite que o servidor on-primisses acessa storage do s3 na aws, logo é um serviço hibrido, usado para backup, tem um sistema de cache gerando uma baixa latência na casa do milisegundos.
A aws te envia um dispositivo físico chamado storage gateway para usar esse serviço
usando esse serviço, existem 3 opções:
File gateway: utiliza o mesmo sistema do s3
Volume gateway: utiliza como um block storage
backup gateway: pode ser block storage ou file do s3

O AWS Storage Gateway Tape Gateway permite substituir o uso de fitas físicas no local por fitas virtuais na AWS sem alterar os fluxos de trabalho de backup existentes. O Tape Gateway emula bibliotecas de fitas físicas, elimina o custo e a complexidade do gerenciamento da infraestrutura de fitas físicas e oferece mais durabilidade do que as fitas físicas.

------------

Amazon S3 File Gateway

Buckets configurados no S3 são acessíveis utilizando os protocolos NFS e SMB.
Os dados mais recentemente acessados são armazenados em cache no File Gateway.
Suporta as classes de armazenamento do S3:
 S3 Standard
 S3 Standard-IA
 S3 One Zone-IA
 S3 Intelligent Tiering
Transição para o S3 Glacier pode ser feita usando uma Política de Ciclo de Vida.
O acesso aos buckets é controlado por funções IAM específicas para cada File Gateway.
O protocolo SMB tem integração com o Active Directory (AD) para autenticação de usuários.

------------
Amazon FSx File Gateway

Acesso nativo ao Amazon FSx for Windows File Server.
Cache local para dados acessados com frequência.
Compatibilidade nativa com Windows (SMB, NTFS, Active Directory, etc.).
Útil para compartilhamento de arquivos em grupo e diretórios pessoais.

------------
Volume Gateway

Armazenamento em bloco utilizando o protocolo iSCSI, com suporte de S3.
Backups baseados em snapshots do EBS, que ajudam a restaurar volumes on-premises.
Volumes em cache: acesso de baixa latência aos dados mais recentes.
Volumes armazenados: o conjunto completo de dados fica on-premises, com backups agendados para o S3.

------------
Tape Gateway

Algumas empresas ainda utilizam fitas físicas para seus processos de backup.
Com o Tape Gateway, as empresas podem manter os mesmos processos, mas na nuvem.
Virtual Tape Library (VTL), com suporte ao Amazon S3 e Glacier.
Realiza o backup de dados utilizando processos baseados em fitas existentes (e interface iSCSI).
Compatível com os principais fornecedores de software de backup.

------------

Storage Gateway – Hardware Appliance

Ao utilizar o Storage Gateway, é necessário ter virtualização on-premises.
Se isso não for viável, pode-se usar um Storage Gateway Hardware Appliance.
O appliance pode ser comprado no amazon.com.
Funciona com File Gateway, Volume Gateway e Tape Gateway.
Inclui os recursos necessários de CPU, memória, rede e cache SSD.
Útil para backups diários via NFS em pequenos data centers.

==================================================================================

AWS Transfer Family

Serviço totalmente gerenciado para transferências de arquivos para dentro e para fora do Amazon S3 ou Amazon EFS, utilizando o protocolo FTP.
Protocolos Suportados:
AWS Transfer for FTP (File Transfer Protocol).
AWS Transfer for FTPS (File Transfer Protocol over SSL).
AWS Transfer for SFTP (Secure File Transfer Protocol).

Características:

Infraestrutura gerenciada, escalável, confiável e altamente disponível (multi-AZ).
Pagamento por endpoint provisionado por hora e transferências de dados em GB.
Armazena e gerencia as credenciais dos usuários dentro do serviço.
Integração com sistemas de autenticação existentes (Microsoft Active Directory, LDAP, Okta, Amazon Cognito, personalizados).

Casos de uso:
Compartilhamento de arquivos, conjuntos de dados públicos, CRM, ERP, entre outros.

------------

AWS DataSync

O AWS DataSync pode ser usado para mover grandes quantidades de dados online entre o armazenamento local e o Amazon S3 ou o Amazon Elastic File System (Amazon EFS). O DataSync elimina ou lida automaticamente com muitas dessas tarefas, incluindo tarefas de cópia de script, agendamento e monitoramento de transferências, validação de dados e otimização da utilização da rede. O datastore de origem pode usar servidores de arquivos que se comunicam usando o protocolo SMB (Server Message Block).

Movimento de grandes quantidades de dados para dentro e fora da AWS.

Fontes e Destinos de Transferência:
 On-premises / outras nuvens para AWS (NFS, SMB, HDFS, S3 API...), requer agente.
 AWS para AWS (diferentes serviços de armazenamento), não é necessário agente.

Destinos de sincronização suportados:
 Amazon S3 (todas as classes de armazenamento, incluindo Glacier).
 Amazon EFS.
 Amazon FSx (Windows, Lustre, NetApp, OpenZFS, etc.).

Características:
 As tarefas de replicação podem ser agendadas em intervalos horários, diários ou semanais.
 Permissões de arquivos e metadados são preservados (NFS POSIX, SMB, etc.).
 Uma tarefa com agente pode transferir dados a uma taxa de 10 Gbps, com a possibilidade de configurar um limite de largura de banda.

------------

AWS DataSync – Transferência entre Serviços de Armazenamento da AWS

AWS DataSync permite transferir dados de forma eficiente entre diferentes serviços de armazenamento da AWS.
Não é necessário utilizar agente quando a transferência ocorre dentro da AWS (por exemplo, de Amazon S3 para Amazon EFS, ou entre diferentes instâncias do Amazon FSx).

Exemplos de Transferência entre Serviços AWS:

Amazon S3 para Amazon EFS
Amazon S3 para Amazon FSx (Windows, Lustre, NetApp, OpenZFS)
Amazon EFS para Amazon FSx

A ferramenta é ideal para migrar dados entre diferentes camadas de armazenamento da AWS ou entre diferentes regiões da nuvem, sem complicação, garantindo alta performance e preservação dos metadados.

==================================================================================
Comparação de Armazenamento da AWS

S3: Armazenamento de objetos (ideal para armazenar dados como arquivos, imagens e backups).
S3 Glacier: Arquivamento de objetos (solução de baixo custo para armazenar dados raramente acessados).
EBS volumes: Armazenamento em rede para uma instância EC2 por vez (para volumes persistentes de dados).
Instance Storage: Armazenamento físico para a sua instância EC2 (oferece alto IOPS e desempenho rápido).
EFS: Sistema de arquivos em rede para instâncias Linux, compatível com POSIX (acesso simultâneo de múltiplas instâncias).
FSx for Windows: Sistema de arquivos em rede para servidores Windows (suporta SMB e NTFS).
FSx for Lustre: Sistema de arquivos de alto desempenho para computação de alto desempenho (HPC) em Linux.
FSx for NetApp ONTAP: Compatibilidade de sistemas operacionais e protocolos (suporta NFS, SMB, iSCSI).
FSx for OpenZFS: Sistema de arquivos gerenciado baseado no ZFS, ideal para workloads de dados intensivos.
Storage Gateway: Integração entre S3 e FSx com File Gateway, Volume Gateway (cache e armazenado) e Tape Gateway.
Transfer Family: Interface FTP, FTPS, SFTP sobre Amazon S3 ou Amazon EFS.
DataSync: Agendamento de sincronização de dados on-premises para AWS, ou AWS para AWS.
Snowcone / Snowball / Snowmobile: Soluções físicas para mover grandes quantidades de dados para a nuvem.
Database: Armazenamento especializado para workloads específicos, geralmente com indexação e consultas (ex: Amazon RDS, DynamoDB).

==================================================================================
DMS – Serviço de Migração de Banco de Dados (Database Migration Service)

- Migra bancos de dados para a AWS de forma rápida e segura, com resiliência e capacidade de autorrecuperação.
- O banco de dados de origem permanece disponível durante a migração.
- Suporta:
	* Migrações homogêneas: ex. Oracle para Oracle.
	* Migrações heterogêneas: ex. Microsoft SQL Server para Aurora.
- Replicação contínua de dados utilizando CDC (Change Data Capture).
- É necessário criar uma instância EC2 para executar as tarefas de replicação.


==================================================================================

Amazon Athena

Serviço de consulta serverless para analisar dados armazenados no Amazon S3.
Utiliza a linguagem SQL padrão para consultar os arquivos (baseado no Presto).
Suporta CSV, JSON, ORC, Avro e Parquet.
Preço: $5,00 por TB de dados analisados.
Comumente usado com o Amazon QuickSight para relatórios/painéis de controle.
Casos de uso:
  Business Intelligence (BI), análise e relatórios.
  Análise de logs: VPC Flow Logs, ELB Logs, CloudTrail Trails, etc.
Dica para prova:
 Para analisar dados no S3 usando SQL serverless, utilize o Athena.

------------
Amazon Athena – Melhoria de Desempenho 

- Use dados em formato colunar para reduzir custos (menos dados escaneados).
- Apache Parquet ou ORC são recomendados.
- Grande melhoria no desempenho.
- Use o AWS Glue para converter seus dados para Parquet ou ORC.
- Comprimir os dados reduz o tamanho das consultas (bzip2, gzip, lz4, snappy, zlib, zstd…).
- Particione conjuntos de dados no S3 para facilitar consultas em colunas virtuais:

s3://seuBucket/caminhoParaTabela/
<NOME_DA_PARTIÇÃO>=<VALOR>
<NOME_DA_PARTIÇÃO>=<VALOR>
<NOME_DA_PARTIÇÃO>=<VALOR>

Exemplo: s3://athena-examples/flight/parquet/year=1991/month=1/day=1/
Use arquivos maiores (> 128 MB) para minimizar overhead

------------

Amazon Athena – Consulta Federada
- Permite executar consultas SQL em dados armazenados em fontes relacionais, não relacionais, objetos e fontes personalizadas (AWS ou on-premises).
- Usa Conectores de Fonte de Dados, que rodam no AWS Lambda, para executar consultas federadas (ex.: CloudWatch Logs, DynamoDB, RDS, etc.).
- Os resultados das consultas podem ser armazenados no Amazon S3.

==================================================================================

Amazon OpenSearch Service
O Amazon OpenSearch é o sucessor do Amazon Elasticsearch.
No DynamoDB, as consultas só podem ser feitas pela chave primária ou índices.
Com o OpenSearch, você pode pesquisar qualquer campo, incluindo correspondências parciais.
É comum usar o OpenSearch como complemento a outro banco de dados.
Dois modos:
 - Cluster gerenciado
 - Cluster serverless
Não suporta SQL nativamente (pode ser habilitado via um plugin).
Ingestão de dados a partir do Kinesis Data Firehose, AWS IoT e CloudWatch Logs.
Segurança através de Cognito & IAM, criptografia KMS e TLS.
Vem com o OpenSearch Dashboards (para visualização de dados).

==================================================================================

Amazon EMR 
EMR significa "Elastic MapReduce".
O EMR ajuda a criar clusters Hadoop (Big Data) para analisar e processar grandes volumes de dados.
Os clusters podem ser compostos por centenas de instâncias EC2.
O EMR vem com Apache Spark, HBase, Presto, Flink, entre outros.
O EMR cuida de todo o provisionamento e configuração.
Oferece autoescalabilidade e integração com instâncias Spot.
Casos de uso:
 - Processamento de dados
 - Aprendizado de máquina
 - Indexação de sites
 - Big Data


Amazon EMR – Tipos de Nós e Opções de Compra 
Nó Mestre (Master Node): Gerencia o cluster, coordena as operações e gerencia a saúde – execução prolongada.
Nó Core (Core Node): Executa tarefas e armazena dados – execução prolongada.
Nó de Tarefa (Task Node) (opcional): Apenas para executar tarefas – geralmente instâncias Spot.
Opções de Compra:
 - On-demand (Sob demanda): Confiável, previsível, não será terminado.
 - Reserved (Reservado) (mínimo de 1 ano): Economia de custos (o EMR usará automaticamente se disponível).
 - Instâncias Spot: Mais baratas, podem ser terminadas, menos confiáveis.
Pode-se ter cluster de longa duração ou cluster temporário (transitório).

==================================================================================

Amazon QuickSight 

Serviço de business intelligence sem servidor, alimentado por machine learning, para criar painéis interativos.
Rápido, automaticamente escalável, incorporável, com preço por sessão.
Casos de uso:
 - Análise de negócios
 - Criação de visualizações
 - Execução de análises ad-hoc
 - Obtenção de insights de negócios utilizando dados
 - Integrado com RDS, Aurora, Athena, Redshift, S3, etc.
 - Cálculo em memória usando o motor SPICE, caso os dados sejam importados para o QuickSight.
 - Edição Enterprise: Possibilidade de configurar segurança de nível de coluna (CLS).

QuickSight – Painéis e Análise 🚀
Defina usuários (versão padrão) e grupos (versão enterprise).
Esses usuários e grupos existem somente dentro do QuickSight, não no IAM.
Um painel (Dashboard):
 - É um snapshot somente leitura de uma análise que pode ser compartilhado.
 - Preserva a configuração da análise (filtros, parâmetros, controles, ordenação).
 - Você pode compartilhar a análise ou o painel com usuários ou grupos.
 - Para compartilhar um painel, é necessário publicá-lo primeiro.
 - Usuários que visualizam o painel também podem ver os dados subjacentes.


==================================================================================

AWS Lake Formation
Data lake = lugar centralizado para armazenar todos os seus dados com fins analíticos.
Serviço totalmente gerenciado que facilita a criação de um data lake em poucos dias.
Descubra, limpe, transforme e ingira dados em seu Data Lake.
Automatiza muitas etapas manuais complexas (coleta, limpeza, movimentação, catalogação de dados...) e deduplica (usando ML Transforms).
Combina dados estruturados e não estruturados no data lake.
Modelos de origem prontos para S3, RDS, Bancos de Dados Relacionais e NoSQL...
Controle de Acesso detalhado para suas aplicações (nível de linha e de coluna).
Construído sobre o AWS Glue.

==================================================================================

Amazon Managed Streaming for Apache Kafka (Amazon MSK) 🚀
 - Alternativa ao Amazon Kinesis.
 - Apache Kafka totalmente gerenciado na AWS.
 - Permite criar, atualizar e excluir clusters.
 - O MSK cria e gerencia nós de brokers Kafka e nós do Zookeeper para você.
 - Implante o cluster MSK na sua VPC, multi-AZ (até 3 para alta disponibilidade).
 - Recuperação automática de falhas comuns do Apache Kafka.
 - Dados armazenados em volumes EBS pelo tempo que você desejar.
MSK Serverless
  Execute Apache Kafka no MSK sem gerenciar a capacidade.
  O MSK provisiona recursos automaticamente e escalona computação e armazenamento.

Kinesis Data Streams vs. Amazon MSK

Kinesis Data Streams
Limite de tamanho da mensagem: 1 MB
Data Streams com Shards
Divisão e mesclagem de Shards
Criptografia em trânsito com TLS
Criptografia em repouso com KMS

Amazon MSK
1MB padrão, configurável para maior (ex: 10MB)
Tópicos Kafka com Partições
Só é possível adicionar partições a um tópico
Criptografia em trânsito PLAINTEXT ou TLS
Criptografia em repouso com KMS

==================================================================================

Amazon Rekognition
- Encontre objetos, pessoas, texto, cenas em imagens e vídeos usando ML.
- Análise facial e pesquisa facial para verificação de usuários, contagem de pessoas.
- Crie um banco de dados de "rostos familiares" ou compare com celebridades.
Casos de uso:
- Rotulagem
- Moderação de conteúdo
- Detecção de texto
- Detecção e análise facial (gênero, faixa etária, emoções…)
- Pesquisa e verificação facial
- Reconhecimento de celebridades
- Análise de trajetória (ex: para análise de jogos esportivos)

Amazon Rekognition – Moderação de Conteúdo
- Detecta conteúdo inapropriado, indesejado ou ofensivo (imagens e vídeos).
- Usado em mídias sociais, mídia de transmissão, publicidade e e-commerce para criar uma experiência de usuário mais segura.
- Defina um limite mínimo de confiança para itens que serão sinalizados.
- Sinalize conteúdo sensível para análise manual no Amazon Augmented AI (A2I).
- Ajuda a cumprir regulamentos.

Amazon Transcribe
- Converte automaticamente fala em texto.
- Utiliza um processo de aprendizado profundo chamado reconhecimento automático de fala (ASR) para converter fala em texto de forma rápida e precisa.
- Remove automaticamente Informações Pessoais Identificáveis (PII) usando Redação.
- Suporta Identificação Automática de Idioma para áudios multilíngues.
- Casos de uso:
  - Transcrever chamadas de atendimento ao cliente.
  - Automatizar legendas e subtítulos.
  - Gerar metadados para ativos de mídia e criar um arquivo totalmente pesquisável.


Amazon Polly
- Converte texto em fala realista usando aprendizado profundo.
- Permite criar aplicações que falam.

Amazon Polly – Lexicon & SSML
- Personalize a pronúncia das palavras com lexicons de pronúncia.
- Palavras estilizadas: St3ph4ne => "Stephane"
- Siglas: AWS => "Amazon Web Services"
- Faça o upload dos lexicons e use-os na operação SynthesizeSpeech.
- Gere fala a partir de texto simples ou de documentos marcados com SSML (Speech Synthesis Markup Language) – permite maior personalização:
  - enfatizar palavras ou frases específicas,
  - usar pronúncia fonética,
  - incluir sons de respiração, sussurros,
  - usar o estilo de fala Newscaster.
  

Amazon Translate
- Tradução de linguagem natural e precisa.
- O Amazon Translate permite localizar conteúdo — como sites e aplicativos — para usuários internacionais, e traduzir facilmente grandes volumes de texto 
de forma eficiente.
==================================================================================

Amazon Comprehend
- Para Processamento de Linguagem Natural (NLP)
- Serviço totalmente gerenciado e sem servidor
- Usa aprendizado de máquina para encontrar insights e relações no texto
- Detecta o idioma do texto
- Extrai frases-chave, lugares, pessoas, marcas ou eventos
- Compreende se o texto é positivo ou negativo
- Analisa o texto utilizando tokenização e partes da fala
- Organiza automaticamente uma coleção de arquivos de texto por tópico
- Exemplos de casos de uso:
  - Analisar interações com clientes (e-mails) para identificar o que leva a uma experiência positiva ou negativa
  - Criar e agrupar artigos por tópicos que o Comprehend descobrirá
  

Amazon Comprehend Medical
- O Amazon Comprehend Medical detecta e retorna informações úteis em textos clínicos não estruturados:
- Notas dos médicos
- Sumários de alta
- Resultados de exames
- Notas de caso
- Utiliza NLP para detectar Informações de Saúde Protegidas (PHI) – API DetectPHI
- Armazene seus documentos no Amazon S3, analise dados em tempo real com Kinesis Data Firehose, ou use Amazon Transcribe para transcrever narrativas de 
pacientes em texto que pode ser analisado pelo Amazon Comprehend Medical.


==================================================================================

Amazon SageMaker
- Serviço totalmente gerenciado para desenvolvedores / cientistas de dados criarem modelos de Machine Learning (ML)
- Normalmente, é difícil realizar todos os processos em um único local e provisionar servidores
- Processo de Machine Learning (simplificado): prever sua pontuação em um exame

==================================================================================

Amazon Forecast
Serviço totalmente gerenciado que usa Machine Learning para fornecer previsões altamente precisas
Exemplo: prever as vendas futuras de uma capa de chuva
50% mais preciso do que olhar os dados em si
Reduz o tempo de previsão de meses para horas
Casos de uso: Planejamento de Demanda de Produto, Planejamento Financeiro, Planejamento de Recursos

==================================================================================

Amazon Kendra
Serviço de pesquisa de documentos totalmente gerenciado, impulsionado por Machine Learning
Extrai respostas dentro de um documento (texto, pdf, HTML, PowerPoint, MS Word, FAQs…)
Capacidades de pesquisa em linguagem natural
Aprende com interações/feedback do usuário para promover resultados preferenciais (Aprendizado Incremental)
Capacidade de ajustar manualmente os resultados da pesquisa (importância dos dados, frescor, personalizados

==================================================================================

Amazon Personalize
Serviço totalmente gerenciado de ML para criar aplicativos com recomendações personalizadas em tempo real
Exemplo: recomendações personalizadas de produtos/reclassificação, marketing direto personalizado
Exemplo: O usuário comprou ferramentas de jardinagem, forneça recomendações sobre o próximo item a ser comprado
Mesma tecnologia usada pelo Amazon.com
Integra-se a sites existentes, aplicativos, SMS, sistemas de marketing por e-mail, etc.
Implementação em dias, não meses (você não precisa construir, treinar e implantar soluções de ML)
Casos de uso: lojas de varejo, mídia e entretenimento...

==================================================================================

Amazon Textract
- Extrai automaticamente texto, escrita manual e dados de quaisquer documentos digitalizados usando IA e ML
- Extrai dados de formulários e tabelas
- Lê e processa qualquer tipo de documento (PDFs, imagens, …)
- Casos de uso:
  - Serviços financeiros (ex.: faturas, relatórios financeiros)
  - Saúde (ex.: registros médicos, reivindicações de seguro)
  - Setor público (ex.: formulários fiscais, documentos de identidade, passaportes)

==================================================================================

AWS Machine Learning - Resumo
- Rekognition: detecção de faces, rotulagem, reconhecimento de celebridades
- Transcribe: áudio para texto (ex.: legendas)
- Polly: texto para áudio
- Translate: traduções
- Lex: construir bots conversacionais – chatbots
- Connect: centro de contato na nuvem
- Comprehend: processamento de linguagem natural
- SageMaker: aprendizado de máquina para desenvolvedores e cientistas de dados
- Forecast: criar previsões altamente precisas
- Kendra: mecanismo de busca com poder de ML
- Personalize: recomendações personalizadas em tempo real
- Textract: detectar texto e dados em documentos
==================================================================================





